{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_si4Ag7w8pL"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Takes exploratory data and fits variations of the DDM.\n",
    "\n",
    "DDM: average-signal\n",
    "\n",
    "Details: Take every signal that the subject saw in a trial, and average their values. Feed that into a DDM as a time-invariant signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H25E_vlnuwiK",
    "outputId": "78fdf1bf-2017-40b8-8b89-d5accd094091"
   },
   "outputs": [],
   "source": [
    "# Install (package verification, PyDDM, timer, parallelization)\n",
    "#!pip install paranoid-scientist\n",
    "#!pip install pyddm\n",
    "#!pip install pytictoc  \n",
    "#!pip install pathos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from pytictoc import TicToc\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pyddm as ddm\n",
    "from pyddm import Model, Sample, FitResult, Fittable, Fitted, ICPoint, set_N_cpus\n",
    "from pyddm.models import NoiseConstant, BoundConstant, OverlayChain, OverlayNonDecision, OverlayUniformMixture, LossRobustBIC\n",
    "from pyddm.functions import fit_adjust_model, display_model\n",
    "import pyddm.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "datadir = \"D:\\\\OneDrive - California Institute of Technology\\\\PhD\\\\Rangel Lab\\\\2023-common-consequence\\\\data\\\\processed_data\"\n",
    "ddmdir = \"D:\\\\OneDrive - California Institute of Technology\\\\PhD\\\\Rangel Lab\\\\2023-common-consequence\\\\analysis\\\\outputs\\\\ddm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fitting?\n",
    "fitting = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallel settings\n",
    "ncpu = multiprocessing.cpu_count()-1 # always save one core\n",
    "ncpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean Raw Data\n",
    "\n",
    "rawdata_in: odd trials used for in-sample data for model fitting.\n",
    "\n",
    "rawdata_out: even trials used for out-sample data for model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>type</th>\n",
       "      <th>rt</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>vDiff_ab</th>\n",
       "      <th>choice_ab</th>\n",
       "      <th>vA</th>\n",
       "      <th>vB</th>\n",
       "      <th>choice_lr</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9156374</td>\n",
       "      <td>1</td>\n",
       "      <td>AB</td>\n",
       "      <td>5.9680</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>32.25</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9156374</td>\n",
       "      <td>2</td>\n",
       "      <td>AB</td>\n",
       "      <td>3.9200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>26.25</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9156374</td>\n",
       "      <td>3</td>\n",
       "      <td>AB</td>\n",
       "      <td>4.0450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>24.75</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9156374</td>\n",
       "      <td>4</td>\n",
       "      <td>AB</td>\n",
       "      <td>4.6300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>29.25</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9156374</td>\n",
       "      <td>5</td>\n",
       "      <td>AB</td>\n",
       "      <td>5.0520</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>9158924</td>\n",
       "      <td>36</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>5.1217</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-20.65</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>41.65</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>9158924</td>\n",
       "      <td>37</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>3.9959</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-23.10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>44.10</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>9158924</td>\n",
       "      <td>38</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>4.2567</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>36.75</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>9158924</td>\n",
       "      <td>39</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>8.4685</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-5.95</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>26.95</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>9158924</td>\n",
       "      <td>40</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>1.8107</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  trial  type      rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
       "0     9156374      1    AB  5.9680  0.5  0.3     -2.25          0  30  32.25   \n",
       "1     9156374      2    AB  3.9200  0.5  0.3      3.75          1  30  26.25   \n",
       "2     9156374      3    AB  4.0450  0.5  0.3      5.25          1  30  24.75   \n",
       "3     9156374      4    AB  4.6300  0.5  0.3      0.75          0  30  29.25   \n",
       "4     9156374      5    AB  5.0520  0.5  0.3      0.00          0  30  30.00   \n",
       "...       ...    ...   ...     ...  ...  ...       ...        ...  ..    ...   \n",
       "1439  9158924     36  ApBp  5.1217  0.7  0.7    -20.65          0  21  41.65   \n",
       "1440  9158924     37  ApBp  3.9959  0.7  0.7    -23.10          0  21  44.10   \n",
       "1441  9158924     38  ApBp  4.2567  0.7  0.7    -15.75          0  21  36.75   \n",
       "1442  9158924     39  ApBp  8.4685  0.7  0.7     -5.95          1  21  26.95   \n",
       "1443  9158924     40  ApBp  1.8107  0.7  0.7      3.85          1  21  17.15   \n",
       "\n",
       "      choice_lr   H  \n",
       "0             0  75  \n",
       "1             1  35  \n",
       "2             1  25  \n",
       "3             1  55  \n",
       "4             1  60  \n",
       "...         ...  ..  \n",
       "1439          1  85  \n",
       "1440          1  90  \n",
       "1441          0  75  \n",
       "1442          1  55  \n",
       "1443          0  35  \n",
       "\n",
       "[1444 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "data = pd.read_csv(datadir+\"\\\\pilotdata.csv\")\n",
    "\n",
    "# Ceiling of Maximum RT for PyDDM\n",
    "maxRT = math.ceil(max(data.rt))\n",
    "\n",
    "# Display\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DDM: Condition Invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the average stimulus DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a drift subclass so drift can vary with stimulus.\n",
    "class DriftRate(ddm.models.Drift):\n",
    "  name = \"Drift depends linearly on value difference\"\n",
    "  required_parameters = [\"driftrate\"] # Parameters we want to include in the model.\n",
    "  required_conditions = [\"vDiff_ab\"] # The column in your sample data that modulates the parameters above.\n",
    "  def get_drift(self, conditions, **kwargs):\n",
    "    return self.driftrate * conditions[\"vDiff_ab\"]\n",
    "\n",
    "# Define the model.\n",
    "model_ci = Model(name=\"Standard DDM that does not distinguish between AB and A'B' choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a466053f5e34d58a940fb4b8c566673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.1108150670698409, continuous_update=False, description='drifâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a94443f552614c73a6bd28759c756748",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive plot! Play with the variables!\n",
    "vDiff_ab = np.sort(data.vDiff_ab.unique())\n",
    "pyddm.plot.model_gui_jupyter(model=model_ci, conditions={\"vDiff_ab\":vDiff_ab.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: Condition Invariant.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data[data[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_ci = fit_adjust_model(sample=ddm_data, model=model_ci,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_ci)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_ci_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract parameters and BIC for the model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.614476</td>\n",
       "      <td>0.051440</td>\n",
       "      <td>0.354061</td>\n",
       "      <td>-0.099547</td>\n",
       "      <td>0.094187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208.050035</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>0.421540</td>\n",
       "      <td>0.176852</td>\n",
       "      <td>0.092509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235.378416</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.400642</td>\n",
       "      <td>0.314949</td>\n",
       "      <td>0.094061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202.590692</td>\n",
       "      <td>0.029411</td>\n",
       "      <td>0.256057</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>0.099571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244.179249</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.432866</td>\n",
       "      <td>-0.149773</td>\n",
       "      <td>0.086832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199.171074</td>\n",
       "      <td>0.040756</td>\n",
       "      <td>0.532894</td>\n",
       "      <td>-0.050570</td>\n",
       "      <td>0.090629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>227.957362</td>\n",
       "      <td>0.024584</td>\n",
       "      <td>0.652739</td>\n",
       "      <td>0.332271</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200.435388</td>\n",
       "      <td>0.017127</td>\n",
       "      <td>0.359543</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>0.095878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>223.651085</td>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.370095</td>\n",
       "      <td>-0.204548</td>\n",
       "      <td>0.080100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>198.422078</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.267747</td>\n",
       "      <td>0.044239</td>\n",
       "      <td>0.084693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>214.030271</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.528341</td>\n",
       "      <td>-0.080456</td>\n",
       "      <td>0.090477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>193.729171</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.468458</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>0.097192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200.076947</td>\n",
       "      <td>0.039294</td>\n",
       "      <td>0.457229</td>\n",
       "      <td>-0.125465</td>\n",
       "      <td>0.098153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>176.304062</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.335201</td>\n",
       "      <td>0.106155</td>\n",
       "      <td>0.092399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>171.513208</td>\n",
       "      <td>0.046134</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>-0.041360</td>\n",
       "      <td>0.091495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>205.735467</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.425349</td>\n",
       "      <td>-0.165756</td>\n",
       "      <td>0.094159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>191.076182</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.296072</td>\n",
       "      <td>-0.146101</td>\n",
       "      <td>0.096476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>171.106183</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.189458</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.083626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>240.941013</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.392511</td>\n",
       "      <td>-0.211138</td>\n",
       "      <td>0.097398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>209.104485</td>\n",
       "      <td>0.046922</td>\n",
       "      <td>0.355877</td>\n",
       "      <td>-0.304176</td>\n",
       "      <td>0.096532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>190.496768</td>\n",
       "      <td>0.030456</td>\n",
       "      <td>0.386742</td>\n",
       "      <td>-0.160806</td>\n",
       "      <td>0.099985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>194.267732</td>\n",
       "      <td>0.037052</td>\n",
       "      <td>0.512639</td>\n",
       "      <td>0.145172</td>\n",
       "      <td>0.097944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>198.016259</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>0.349514</td>\n",
       "      <td>-0.052980</td>\n",
       "      <td>0.099983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>132.169092</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.634106</td>\n",
       "      <td>-0.253628</td>\n",
       "      <td>0.095128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>200.937449</td>\n",
       "      <td>0.046573</td>\n",
       "      <td>0.537331</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0.095763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>228.597296</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.257335</td>\n",
       "      <td>0.558280</td>\n",
       "      <td>0.099234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>195.927336</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>0.617403</td>\n",
       "      <td>0.108030</td>\n",
       "      <td>0.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>219.793169</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>0.334385</td>\n",
       "      <td>-0.108161</td>\n",
       "      <td>0.083379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>199.339988</td>\n",
       "      <td>0.017805</td>\n",
       "      <td>0.396239</td>\n",
       "      <td>-0.196035</td>\n",
       "      <td>0.077419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>219.042388</td>\n",
       "      <td>0.019305</td>\n",
       "      <td>0.408597</td>\n",
       "      <td>-0.093732</td>\n",
       "      <td>0.057553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>163.085246</td>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.288635</td>\n",
       "      <td>0.267479</td>\n",
       "      <td>0.050580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>168.522897</td>\n",
       "      <td>0.047802</td>\n",
       "      <td>0.304181</td>\n",
       "      <td>0.153476</td>\n",
       "      <td>0.090843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>209.843890</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.298346</td>\n",
       "      <td>0.122056</td>\n",
       "      <td>0.071223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>191.214630</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.447725</td>\n",
       "      <td>-0.107573</td>\n",
       "      <td>0.091328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>152.707693</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.378048</td>\n",
       "      <td>-0.062594</td>\n",
       "      <td>0.069296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>220.125024</td>\n",
       "      <td>0.038672</td>\n",
       "      <td>0.442751</td>\n",
       "      <td>-0.293621</td>\n",
       "      <td>0.082915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>161.138775</td>\n",
       "      <td>0.087649</td>\n",
       "      <td>0.515378</td>\n",
       "      <td>-0.043320</td>\n",
       "      <td>0.099337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>196.778289</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>0.406354</td>\n",
       "      <td>-0.044110</td>\n",
       "      <td>0.094491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0   197.614476  0.051440  0.354061 -0.099547  0.094187\n",
       "1   208.050035  0.016715  0.421540  0.176852  0.092509\n",
       "2   235.378416  0.006016  0.400642  0.314949  0.094061\n",
       "3   202.590692  0.029411  0.256057  0.017144  0.099571\n",
       "4   244.179249  0.009191  0.432866 -0.149773  0.086832\n",
       "5   199.171074  0.040756  0.532894 -0.050570  0.090629\n",
       "6   227.957362  0.024584  0.652739  0.332271  0.001509\n",
       "7   200.435388  0.017127  0.359543 -0.001355  0.095878\n",
       "8   223.651085  0.034586  0.370095 -0.204548  0.080100\n",
       "9   198.422078  0.009952  0.267747  0.044239  0.084693\n",
       "10  214.030271  0.015118  0.528341 -0.080456  0.090477\n",
       "11  193.729171  0.042225  0.468458  0.107686  0.097192\n",
       "12  200.076947  0.039294  0.457229 -0.125465  0.098153\n",
       "13  176.304062  0.020042  0.335201  0.106155  0.092399\n",
       "14  171.513208  0.046134  0.312950 -0.041360  0.091495\n",
       "15  205.735467  0.021013  0.425349 -0.165756  0.094159\n",
       "16  191.076182  0.022450  0.296072 -0.146101  0.096476\n",
       "17  171.106183  0.008381  0.189458  0.154533  0.083626\n",
       "18  240.941013  0.011753  0.392511 -0.211138  0.097398\n",
       "19  209.104485  0.046922  0.355877 -0.304176  0.096532\n",
       "20  190.496768  0.030456  0.386742 -0.160806  0.099985\n",
       "21  194.267732  0.037052  0.512639  0.145172  0.097944\n",
       "22  198.016259  0.035278  0.349514 -0.052980  0.099983\n",
       "23  132.169092  0.037773  0.634106 -0.253628  0.095128\n",
       "24  200.937449  0.046573  0.537331 -0.200286  0.095763\n",
       "25  228.597296  0.005602  0.257335  0.558280  0.099234\n",
       "26  195.927336  0.022919  0.617403  0.108030  0.098100\n",
       "27  219.793169  0.017072  0.334385 -0.108161  0.083379\n",
       "28  199.339988  0.017805  0.396239 -0.196035  0.077419\n",
       "29  219.042388  0.019305  0.408597 -0.093732  0.057553\n",
       "30  163.085246  0.036026  0.288635  0.267479  0.050580\n",
       "31  168.522897  0.047802  0.304181  0.153476  0.090843\n",
       "32  209.843890  0.012194  0.298346  0.122056  0.071223\n",
       "33  191.214630  0.021982  0.447725 -0.107573  0.091328\n",
       "34  152.707693  0.016912  0.378048 -0.062594  0.069296\n",
       "35  220.125024  0.038672  0.442751 -0.293621  0.082915\n",
       "36  161.138775  0.087649  0.515378 -0.043320  0.099337\n",
       "37  196.778289  0.022180  0.406354 -0.044110  0.094491"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_ci_bic = []\n",
    "model_ci_drift = []\n",
    "model_ci_noise = []\n",
    "model_ci_bias = []\n",
    "model_ci_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_ci_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_ci_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_ci_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_ci_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_ci_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_ci_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_ci_bic, \"drift\":model_ci_drift, \"noise\":model_ci_noise, \"bias\":model_ci_bias, \"ndt\":model_ci_ndt}\n",
    "indiv_model_ci = pd.DataFrame(data=d)\n",
    "indiv_model_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means of BIC and Estimates\n",
    "\n",
    "Confidence intervals assume normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>198.765020</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.403298</td>\n",
       "      <td>-0.015494</td>\n",
       "      <td>0.087168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>3.945812</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.030632</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>191.031228</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.369004</td>\n",
       "      <td>-0.075533</td>\n",
       "      <td>0.081353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>206.498812</td>\n",
       "      <td>0.033323</td>\n",
       "      <td>0.437593</td>\n",
       "      <td>0.044545</td>\n",
       "      <td>0.092983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean      198.765020  0.028062  0.403298 -0.015494  0.087168\n",
       "se          3.945812  0.002684  0.017497  0.030632  0.002967\n",
       "ci_lower  191.031228  0.022801  0.369004 -0.075533  0.081353\n",
       "ci_upper  206.498812  0.033323  0.437593  0.044545  0.092983"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_ci = pd.DataFrame(data={\"mean\":indiv_model_ci.mean(), \n",
    "                                        \"se\":indiv_model_ci.sem(),\n",
    "                                        \"ci_lower\":indiv_model_ci.mean()-1.96*indiv_model_ci.sem(),\n",
    "                                        \"ci_upper\":indiv_model_ci.mean()+1.96*indiv_model_ci.sem()}).T\n",
    "summstats_model_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DDM: Separately by Block (p,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate datasets by type (AB or ApBp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject  trial type     rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
      "0  9156374      1   AB  5.968  0.5  0.3     -2.25          0  30  32.25   \n",
      "1  9156374      2   AB  3.920  0.5  0.3      3.75          1  30  26.25   \n",
      "\n",
      "   choice_lr   H  \n",
      "0          0  75  \n",
      "1          1  35  \n",
      "   subject  trial type     rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
      "0  9156374      1   AB  5.968  0.5  0.3     -2.25          0  30  32.25   \n",
      "1  9156374      2   AB  3.920  0.5  0.3      3.75          1  30  26.25   \n",
      "\n",
      "   choice_lr   H  \n",
      "0          0  75  \n",
      "1          1  35  \n"
     ]
    }
   ],
   "source": [
    "data_ab = data[data.type==\"AB\"]\n",
    "data_apbp = data[data.type==\"ApBp\"]\n",
    "\n",
    "print(data_ab.head(2))\n",
    "print(data_ab.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DDM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a drift subclass so drift can vary with stimulus.\n",
    "class DriftRate(ddm.models.Drift):\n",
    "  name = \"Drift depends linearly on value difference\"\n",
    "  required_parameters = [\"driftrate\"] # Parameters we want to include in the model.\n",
    "  required_conditions = [\"vDiff_ab\"] # The column in your sample data that modulates the parameters above.\n",
    "  def get_drift(self, conditions, **kwargs):\n",
    "    return self.driftrate * conditions[\"vDiff_ab\"]\n",
    "\n",
    "# Define the model.\n",
    "model_ab = Model(name=\"Standard DDM fit to AB choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))\n",
    "\n",
    "model_apbp = Model(name=\"Standard DDM fit to ApBp choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: AB.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data_ab.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data_ab[data_ab[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_ab = fit_adjust_model(sample=ddm_data, model=model_ab,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_ab)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_ab_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: ApBp.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data_apbp.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data_apbp[data_apbp[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_apbp = fit_adjust_model(sample=ddm_data, model=model_apbp,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_apbp)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_apbp_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_apbp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract estimates and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.312660</td>\n",
       "      <td>0.058783</td>\n",
       "      <td>0.313904</td>\n",
       "      <td>-0.165942</td>\n",
       "      <td>0.067146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.887612</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.401901</td>\n",
       "      <td>0.201850</td>\n",
       "      <td>0.098725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.778228</td>\n",
       "      <td>0.012515</td>\n",
       "      <td>0.301361</td>\n",
       "      <td>0.250897</td>\n",
       "      <td>0.074616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.909972</td>\n",
       "      <td>0.031255</td>\n",
       "      <td>0.245422</td>\n",
       "      <td>0.106721</td>\n",
       "      <td>0.078875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.130558</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.392878</td>\n",
       "      <td>-0.324815</td>\n",
       "      <td>0.092661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95.995432</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>0.561719</td>\n",
       "      <td>-0.104660</td>\n",
       "      <td>0.080221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>123.185262</td>\n",
       "      <td>0.019538</td>\n",
       "      <td>0.542202</td>\n",
       "      <td>0.369781</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>102.620662</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>-0.248277</td>\n",
       "      <td>0.098520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>118.132514</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.364450</td>\n",
       "      <td>-0.158731</td>\n",
       "      <td>0.081542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.682048</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.310702</td>\n",
       "      <td>0.026457</td>\n",
       "      <td>0.093707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>124.760575</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.475622</td>\n",
       "      <td>-0.136992</td>\n",
       "      <td>0.061149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>98.556269</td>\n",
       "      <td>0.040310</td>\n",
       "      <td>0.471072</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.093565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90.518219</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>0.462004</td>\n",
       "      <td>-0.110851</td>\n",
       "      <td>0.095099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101.160660</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.344502</td>\n",
       "      <td>0.151642</td>\n",
       "      <td>0.098547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73.356560</td>\n",
       "      <td>0.062568</td>\n",
       "      <td>0.335889</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>0.093246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105.262644</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>0.440289</td>\n",
       "      <td>-0.284254</td>\n",
       "      <td>0.090971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>104.601163</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.307022</td>\n",
       "      <td>-0.235243</td>\n",
       "      <td>0.091167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101.472044</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.198710</td>\n",
       "      <td>0.088326</td>\n",
       "      <td>0.085752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>132.299287</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.423419</td>\n",
       "      <td>-0.084560</td>\n",
       "      <td>0.098117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>107.621036</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.308802</td>\n",
       "      <td>-0.454185</td>\n",
       "      <td>0.097837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99.626387</td>\n",
       "      <td>0.028542</td>\n",
       "      <td>0.428676</td>\n",
       "      <td>-0.079358</td>\n",
       "      <td>0.096616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>98.451954</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>0.475276</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>0.090607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95.896772</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.351311</td>\n",
       "      <td>-0.021840</td>\n",
       "      <td>0.080476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>73.579986</td>\n",
       "      <td>0.034267</td>\n",
       "      <td>0.493990</td>\n",
       "      <td>-0.404989</td>\n",
       "      <td>0.099325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111.710060</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.534558</td>\n",
       "      <td>-0.083470</td>\n",
       "      <td>0.093187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>129.320311</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.209897</td>\n",
       "      <td>0.589860</td>\n",
       "      <td>0.055519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>91.650160</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>0.352125</td>\n",
       "      <td>0.094003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>111.821562</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.361402</td>\n",
       "      <td>-0.135620</td>\n",
       "      <td>0.065338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>101.224173</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>0.382945</td>\n",
       "      <td>-0.355394</td>\n",
       "      <td>0.094269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>118.948819</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>-0.008548</td>\n",
       "      <td>0.073059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>93.557402</td>\n",
       "      <td>0.027236</td>\n",
       "      <td>0.255575</td>\n",
       "      <td>0.320105</td>\n",
       "      <td>0.095643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>89.608001</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0.293538</td>\n",
       "      <td>0.146374</td>\n",
       "      <td>0.097945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>94.062152</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.260023</td>\n",
       "      <td>0.109291</td>\n",
       "      <td>0.081706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>104.596994</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.400749</td>\n",
       "      <td>-0.261369</td>\n",
       "      <td>0.082734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>82.809513</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.385072</td>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.073957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>104.701719</td>\n",
       "      <td>0.053920</td>\n",
       "      <td>0.452571</td>\n",
       "      <td>-0.387631</td>\n",
       "      <td>0.098328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>67.932550</td>\n",
       "      <td>0.106446</td>\n",
       "      <td>0.364090</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.090347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>112.295631</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>0.405943</td>\n",
       "      <td>-0.146260</td>\n",
       "      <td>0.081574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0    97.312660  0.058783  0.313904 -0.165942  0.067146\n",
       "1   106.887612  0.018007  0.401901  0.201850  0.098725\n",
       "2   116.778228  0.012515  0.301361  0.250897  0.074616\n",
       "3   104.909972  0.031255  0.245422  0.106721  0.078875\n",
       "4   125.130558  0.001427  0.392878 -0.324815  0.092661\n",
       "5    95.995432  0.058460  0.561719 -0.104660  0.080221\n",
       "6   123.185262  0.019538  0.542202  0.369781  0.004400\n",
       "7   102.620662  0.015448  0.283405 -0.248277  0.098520\n",
       "8   118.132514  0.033262  0.364450 -0.158731  0.081542\n",
       "9   101.682048  0.011473  0.310702  0.026457  0.093707\n",
       "10  124.760575  0.005953  0.475622 -0.136992  0.061149\n",
       "11   98.556269  0.040310  0.471072  0.139960  0.093565\n",
       "12   90.518219  0.043119  0.462004 -0.110851  0.095099\n",
       "13  101.160660  0.016877  0.344502  0.151642  0.098547\n",
       "14   73.356560  0.062568  0.335889 -0.020023  0.093246\n",
       "15  105.262644  0.018110  0.440289 -0.284254  0.090971\n",
       "16  104.601163  0.022456  0.307022 -0.235243  0.091167\n",
       "17  101.472044  0.009334  0.198710  0.088326  0.085752\n",
       "18  132.299287  0.006200  0.423419 -0.084560  0.098117\n",
       "19  107.621036  0.048304  0.308802 -0.454185  0.097837\n",
       "20   99.626387  0.028542  0.428676 -0.079358  0.096616\n",
       "21   98.451954  0.057009  0.475276 -0.002364  0.090607\n",
       "22   95.896772  0.042200  0.351311 -0.021840  0.080476\n",
       "23   73.579986  0.034267  0.493990 -0.404989  0.099325\n",
       "24  111.710060  0.024615  0.534558 -0.083470  0.093187\n",
       "25  129.320311  0.004740  0.209897  0.589860  0.055519\n",
       "26   91.650160  0.009659  0.581443  0.352125  0.094003\n",
       "27  111.821562  0.018684  0.361402 -0.135620  0.065338\n",
       "28  101.224173  0.020581  0.382945 -0.355394  0.094269\n",
       "29  118.948819  0.016342  0.380204 -0.008548  0.073059\n",
       "30   93.557402  0.027236  0.255575  0.320105  0.095643\n",
       "31   89.608001  0.047337  0.293538  0.146374  0.097945\n",
       "32   94.062152  0.015743  0.260023  0.109291  0.081706\n",
       "33  104.596994  0.023810  0.400749 -0.261369  0.082734\n",
       "34   82.809513  0.014270  0.385072 -0.125238  0.073957\n",
       "35  104.701719  0.053920  0.452571 -0.387631  0.098328\n",
       "36   67.932550  0.106446  0.364090  0.092803  0.090347\n",
       "37  112.295631  0.017212  0.405943 -0.146260  0.081574"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_ab_bic = []\n",
    "model_ab_drift = []\n",
    "model_ab_noise = []\n",
    "model_ab_bias = []\n",
    "model_ab_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data_ab.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_ab_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_ab_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_ab_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_ab_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_ab_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_ab_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_ab_bic, \"drift\":model_ab_drift, \"noise\":model_ab_noise, \"bias\":model_ab_bias, \"ndt\":model_ab_ndt}\n",
    "indiv_model_ab = pd.DataFrame(data=d)\n",
    "indiv_model_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.010532</td>\n",
       "      <td>0.045312</td>\n",
       "      <td>0.367774</td>\n",
       "      <td>-0.048118</td>\n",
       "      <td>0.099541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.054843</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>0.435725</td>\n",
       "      <td>0.178335</td>\n",
       "      <td>0.098093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.858334</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.421583</td>\n",
       "      <td>0.340519</td>\n",
       "      <td>0.090151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.605127</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>0.268849</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.092376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.642345</td>\n",
       "      <td>0.028829</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>-0.265369</td>\n",
       "      <td>0.063802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110.163505</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.498142</td>\n",
       "      <td>-0.183972</td>\n",
       "      <td>0.097209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102.625238</td>\n",
       "      <td>0.038103</td>\n",
       "      <td>0.794343</td>\n",
       "      <td>0.291533</td>\n",
       "      <td>0.006331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95.909183</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.325959</td>\n",
       "      <td>0.242095</td>\n",
       "      <td>0.093054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>114.542292</td>\n",
       "      <td>0.036054</td>\n",
       "      <td>0.372955</td>\n",
       "      <td>-0.259397</td>\n",
       "      <td>0.087277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.339464</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.188688</td>\n",
       "      <td>0.130763</td>\n",
       "      <td>0.090501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>83.484650</td>\n",
       "      <td>0.046020</td>\n",
       "      <td>0.531531</td>\n",
       "      <td>-0.251401</td>\n",
       "      <td>0.091931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>104.248719</td>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.461655</td>\n",
       "      <td>0.066254</td>\n",
       "      <td>0.063072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>118.104911</td>\n",
       "      <td>0.038434</td>\n",
       "      <td>0.453281</td>\n",
       "      <td>-0.177244</td>\n",
       "      <td>0.091398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>79.555206</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.287114</td>\n",
       "      <td>0.090258</td>\n",
       "      <td>0.096028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>101.188043</td>\n",
       "      <td>0.038005</td>\n",
       "      <td>0.262878</td>\n",
       "      <td>-0.008755</td>\n",
       "      <td>0.095092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105.787908</td>\n",
       "      <td>0.024836</td>\n",
       "      <td>0.375258</td>\n",
       "      <td>-0.084398</td>\n",
       "      <td>0.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>93.135429</td>\n",
       "      <td>0.022273</td>\n",
       "      <td>0.261362</td>\n",
       "      <td>-0.030723</td>\n",
       "      <td>0.094408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74.499192</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.156495</td>\n",
       "      <td>0.196292</td>\n",
       "      <td>0.091142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>112.093729</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.333041</td>\n",
       "      <td>-0.402379</td>\n",
       "      <td>0.095789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>107.613960</td>\n",
       "      <td>0.049958</td>\n",
       "      <td>0.380869</td>\n",
       "      <td>-0.257850</td>\n",
       "      <td>0.091944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>98.249253</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.346251</td>\n",
       "      <td>-0.147640</td>\n",
       "      <td>0.096733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>99.170374</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.350321</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.092958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>109.568620</td>\n",
       "      <td>0.030223</td>\n",
       "      <td>0.340185</td>\n",
       "      <td>-0.051842</td>\n",
       "      <td>0.081181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64.342608</td>\n",
       "      <td>0.047283</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>-0.274347</td>\n",
       "      <td>0.092958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>94.861249</td>\n",
       "      <td>0.074649</td>\n",
       "      <td>0.517400</td>\n",
       "      <td>-0.301158</td>\n",
       "      <td>0.099852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107.671604</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.253579</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.097336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>101.747841</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.526874</td>\n",
       "      <td>-0.180712</td>\n",
       "      <td>0.094292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>115.195368</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.295262</td>\n",
       "      <td>-0.013883</td>\n",
       "      <td>0.091952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>103.047073</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>0.380055</td>\n",
       "      <td>-0.007112</td>\n",
       "      <td>0.092916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>106.462909</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.419932</td>\n",
       "      <td>-0.137426</td>\n",
       "      <td>0.000924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>74.013216</td>\n",
       "      <td>0.045885</td>\n",
       "      <td>0.261789</td>\n",
       "      <td>0.319417</td>\n",
       "      <td>0.086589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>87.996129</td>\n",
       "      <td>0.047792</td>\n",
       "      <td>0.312919</td>\n",
       "      <td>0.125886</td>\n",
       "      <td>0.088701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>119.964475</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.303642</td>\n",
       "      <td>0.161767</td>\n",
       "      <td>0.098622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>93.470049</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>0.491380</td>\n",
       "      <td>-0.095740</td>\n",
       "      <td>0.098887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>74.842579</td>\n",
       "      <td>0.018388</td>\n",
       "      <td>0.329313</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>0.076799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>122.449480</td>\n",
       "      <td>0.032294</td>\n",
       "      <td>0.418181</td>\n",
       "      <td>-0.281708</td>\n",
       "      <td>0.091546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>93.770097</td>\n",
       "      <td>0.073291</td>\n",
       "      <td>0.559815</td>\n",
       "      <td>-0.096834</td>\n",
       "      <td>0.075396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>85.550257</td>\n",
       "      <td>0.031772</td>\n",
       "      <td>0.346805</td>\n",
       "      <td>0.094368</td>\n",
       "      <td>0.087666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0   108.010532  0.045312  0.367774 -0.048118  0.099541\n",
       "1   110.054843  0.015322  0.435725  0.178335  0.098093\n",
       "2   110.858334 -0.001279  0.421583  0.340519  0.090151\n",
       "3   106.605127  0.028349  0.268849  0.009511  0.092376\n",
       "4   102.642345  0.028829  0.334906 -0.265369  0.063802\n",
       "5   110.163505  0.037922  0.498142 -0.183972  0.097209\n",
       "6   102.625238  0.038103  0.794343  0.291533  0.006331\n",
       "7    95.909183  0.020517  0.325959  0.242095  0.093054\n",
       "8   114.542292  0.036054  0.372955 -0.259397  0.087277\n",
       "9    99.339464  0.009057  0.188688  0.130763  0.090501\n",
       "10   83.484650  0.046020  0.531531 -0.251401  0.091931\n",
       "11  104.248719  0.043093  0.461655  0.066254  0.063072\n",
       "12  118.104911  0.038434  0.453281 -0.177244  0.091398\n",
       "13   79.555206  0.024540  0.287114  0.090258  0.096028\n",
       "14  101.188043  0.038005  0.262878 -0.008755  0.095092\n",
       "15  105.787908  0.024836  0.375258 -0.084398  0.072452\n",
       "16   93.135429  0.022273  0.261362 -0.030723  0.094408\n",
       "17   74.499192  0.007255  0.156495  0.196292  0.091142\n",
       "18  112.093729  0.018390  0.333041 -0.402379  0.095789\n",
       "19  107.613960  0.049958  0.380869 -0.257850  0.091944\n",
       "20   98.249253  0.033565  0.346251 -0.147640  0.096733\n",
       "21   99.170374  0.011612  0.350321  0.506836  0.092958\n",
       "22  109.568620  0.030223  0.340185 -0.051842  0.081181\n",
       "23   64.342608  0.047283  0.695531 -0.274347  0.092958\n",
       "24   94.861249  0.074649  0.517400 -0.301158  0.099852\n",
       "25  107.671604  0.005534  0.253579  0.614527  0.097336\n",
       "26  101.747841  0.033422  0.526874 -0.180712  0.094292\n",
       "27  115.195368  0.015243  0.295262 -0.013883  0.091952\n",
       "28  103.047073  0.014977  0.380055 -0.007112  0.092916\n",
       "29  106.462909  0.022449  0.419932 -0.137426  0.000924\n",
       "30   74.013216  0.045885  0.261789  0.319417  0.086589\n",
       "31   87.996129  0.047792  0.312919  0.125886  0.088701\n",
       "32  119.964475  0.009745  0.303642  0.161767  0.098622\n",
       "33   93.470049  0.023131  0.491380 -0.095740  0.098887\n",
       "34   74.842579  0.018388  0.329313  0.094917  0.076799\n",
       "35  122.449480  0.032294  0.418181 -0.281708  0.091546\n",
       "36   93.770097  0.073291  0.559815 -0.096834  0.075396\n",
       "37   85.550257  0.031772  0.346805  0.094368  0.087666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_apbp_bic = []\n",
    "model_apbp_drift = []\n",
    "model_apbp_noise = []\n",
    "model_apbp_bias = []\n",
    "model_apbp_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data_apbp.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_apbp_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_apbp_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_apbp_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_apbp_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_apbp_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_apbp_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_apbp_bic, \"drift\":model_apbp_drift, \"noise\":model_apbp_noise, \"bias\":model_apbp_bias, \"ndt\":model_apbp_ndt}\n",
    "indiv_model_apbp = pd.DataFrame(data=d)\n",
    "indiv_model_apbp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means of Estimates and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>103.000988</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.381646</td>\n",
       "      <td>-0.036695</td>\n",
       "      <td>0.084750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>2.399852</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.038260</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>98.297278</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.351073</td>\n",
       "      <td>-0.111685</td>\n",
       "      <td>0.079128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>107.704698</td>\n",
       "      <td>0.035639</td>\n",
       "      <td>0.412218</td>\n",
       "      <td>0.038295</td>\n",
       "      <td>0.090372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean      103.000988  0.028842  0.381646 -0.036695  0.084750\n",
       "se          2.399852  0.003468  0.015598  0.038260  0.002868\n",
       "ci_lower   98.297278  0.022046  0.351073 -0.111685  0.079128\n",
       "ci_upper  107.704698  0.035639  0.412218  0.038295  0.090372"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_ab = pd.DataFrame(data={\"mean\":indiv_model_ab.mean(), \n",
    "                                        \"se\":indiv_model_ab.sem(),\n",
    "                                        \"ci_lower\":indiv_model_ab.mean()-1.96*indiv_model_ab.sem(),\n",
    "                                        \"ci_upper\":indiv_model_ab.mean()+1.96*indiv_model_ab.sem()}).T\n",
    "summstats_model_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.811468</td>\n",
       "      <td>0.030059</td>\n",
       "      <td>0.385833</td>\n",
       "      <td>-0.002493</td>\n",
       "      <td>0.085445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>2.235519</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.037725</td>\n",
       "      <td>0.003488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>95.429851</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>-0.076435</td>\n",
       "      <td>0.078608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>104.193085</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.426639</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.092282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean       99.811468  0.030059  0.385833 -0.002493  0.085445\n",
       "se          2.235519  0.002753  0.020820  0.037725  0.003488\n",
       "ci_lower   95.429851  0.024664  0.345026 -0.076435  0.078608\n",
       "ci_upper  104.193085  0.035454  0.426639  0.071449  0.092282"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_apbp = pd.DataFrame(data={\"mean\":indiv_model_apbp.mean(), \n",
    "                                        \"se\":indiv_model_apbp.sem(),\n",
    "                                        \"ci_lower\":indiv_model_apbp.mean()-1.96*indiv_model_apbp.sem(),\n",
    "                                        \"ci_upper\":indiv_model_apbp.mean()+1.96*indiv_model_apbp.sem()}).T\n",
    "summstats_model_apbp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_diff = indiv_model_apbp.noise - indiv_model_ab.noise\n",
    "plt.hist(est_diff)\n",
    "plt.plot((0, 0), (0, 9), scaley = False)\n",
    "plt.xlabel(\"Noise ApBp - Noise AB\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
