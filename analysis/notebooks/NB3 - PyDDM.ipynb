{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_si4Ag7w8pL"
   },
   "source": [
    "# Introduction\n",
    "\n",
    "Takes exploratory data and fits variations of the DDM.\n",
    "\n",
    "DDM: average-signal\n",
    "\n",
    "Details: Take every signal that the subject saw in a trial, and average their values. Feed that into a DDM as a time-invariant signal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H25E_vlnuwiK",
    "outputId": "78fdf1bf-2017-40b8-8b89-d5accd094091"
   },
   "outputs": [],
   "source": [
    "# Install (package verification, PyDDM, timer, parallelization)\n",
    "#!pip install paranoid-scientist\n",
    "#!pip install pyddm\n",
    "#!pip install pytictoc  \n",
    "#!pip install pathos  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "from pytictoc import TicToc\n",
    "import csv\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import multiprocessing\n",
    "import pyddm as ddm\n",
    "from pyddm import Model, Sample, FitResult, Fittable, Fitted, ICPoint, set_N_cpus\n",
    "from pyddm.models import NoiseConstant, BoundConstant, OverlayChain, OverlayNonDecision, OverlayUniformMixture, LossRobustBIC\n",
    "from pyddm.functions import fit_adjust_model, display_model\n",
    "import pyddm.plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "datadir = \"D:\\\\OneDrive - California Institute of Technology\\\\PhD\\\\Rangel Lab\\\\2023-common-consequence\\\\data\\\\processed_data\"\n",
    "ddmdir = \"D:\\\\OneDrive - California Institute of Technology\\\\PhD\\\\Rangel Lab\\\\2023-common-consequence\\\\analysis\\\\outputs\\\\ddm\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run fitting?\n",
    "fitting = False\n",
    "fitting2 = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Parallel settings\n",
    "ncpu = multiprocessing.cpu_count()-1 # always save one core\n",
    "ncpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Clean Raw Data\n",
    "\n",
    "rawdata_in: odd trials used for in-sample data for model fitting.\n",
    "\n",
    "rawdata_out: even trials used for out-sample data for model predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subject</th>\n",
       "      <th>trial</th>\n",
       "      <th>type</th>\n",
       "      <th>rt</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>vDiff_ab</th>\n",
       "      <th>choice_ab</th>\n",
       "      <th>vA</th>\n",
       "      <th>vB</th>\n",
       "      <th>choice_lr</th>\n",
       "      <th>H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9156374</td>\n",
       "      <td>1</td>\n",
       "      <td>AB</td>\n",
       "      <td>5.9680</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>-2.25</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>32.25</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9156374</td>\n",
       "      <td>2</td>\n",
       "      <td>AB</td>\n",
       "      <td>3.9200</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>3.75</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>26.25</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9156374</td>\n",
       "      <td>3</td>\n",
       "      <td>AB</td>\n",
       "      <td>4.0450</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>5.25</td>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>24.75</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9156374</td>\n",
       "      <td>4</td>\n",
       "      <td>AB</td>\n",
       "      <td>4.6300</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>29.25</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9156374</td>\n",
       "      <td>5</td>\n",
       "      <td>AB</td>\n",
       "      <td>5.0520</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>30.00</td>\n",
       "      <td>1</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>9158924</td>\n",
       "      <td>36</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>5.1217</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-20.65</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>41.65</td>\n",
       "      <td>1</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>9158924</td>\n",
       "      <td>37</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>3.9959</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-23.10</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>44.10</td>\n",
       "      <td>1</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>9158924</td>\n",
       "      <td>38</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>4.2567</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-15.75</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>36.75</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>9158924</td>\n",
       "      <td>39</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>8.4685</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>-5.95</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>26.95</td>\n",
       "      <td>1</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>9158924</td>\n",
       "      <td>40</td>\n",
       "      <td>ApBp</td>\n",
       "      <td>1.8107</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.7</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>17.15</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1444 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      subject  trial  type      rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
       "0     9156374      1    AB  5.9680  0.5  0.3     -2.25          0  30  32.25   \n",
       "1     9156374      2    AB  3.9200  0.5  0.3      3.75          1  30  26.25   \n",
       "2     9156374      3    AB  4.0450  0.5  0.3      5.25          1  30  24.75   \n",
       "3     9156374      4    AB  4.6300  0.5  0.3      0.75          0  30  29.25   \n",
       "4     9156374      5    AB  5.0520  0.5  0.3      0.00          0  30  30.00   \n",
       "...       ...    ...   ...     ...  ...  ...       ...        ...  ..    ...   \n",
       "1439  9158924     36  ApBp  5.1217  0.7  0.7    -20.65          0  21  41.65   \n",
       "1440  9158924     37  ApBp  3.9959  0.7  0.7    -23.10          0  21  44.10   \n",
       "1441  9158924     38  ApBp  4.2567  0.7  0.7    -15.75          0  21  36.75   \n",
       "1442  9158924     39  ApBp  8.4685  0.7  0.7     -5.95          1  21  26.95   \n",
       "1443  9158924     40  ApBp  1.8107  0.7  0.7      3.85          1  21  17.15   \n",
       "\n",
       "      choice_lr   H  \n",
       "0             0  75  \n",
       "1             1  35  \n",
       "2             1  25  \n",
       "3             1  55  \n",
       "4             1  60  \n",
       "...         ...  ..  \n",
       "1439          1  85  \n",
       "1440          1  90  \n",
       "1441          0  75  \n",
       "1442          1  55  \n",
       "1443          0  35  \n",
       "\n",
       "[1444 rows x 12 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import\n",
    "data = pd.read_csv(datadir+\"\\\\pilotdata.csv\")\n",
    "\n",
    "# Ceiling of Maximum RT for PyDDM\n",
    "maxRT = math.ceil(max(data.rt))\n",
    "\n",
    "# Display\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DDM: Condition Invariant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the average stimulus DDM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a drift subclass so drift can vary with stimulus.\n",
    "class DriftRate(ddm.models.Drift):\n",
    "  name = \"Drift depends linearly on value difference\"\n",
    "  required_parameters = [\"driftrate\"] # Parameters we want to include in the model.\n",
    "  required_conditions = [\"vDiff_ab\"] # The column in your sample data that modulates the parameters above.\n",
    "  def get_drift(self, conditions, **kwargs):\n",
    "    return self.driftrate * conditions[\"vDiff_ab\"]\n",
    "\n",
    "# Define the model.\n",
    "model_ci = Model(name=\"Standard DDM that does not distinguish between AB and A'B' choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58853ca312f5406792280d3b2bd2bc91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(VBox(children=(FloatSlider(value=0.3850635707705463, continuous_update=False, description='drifâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7f05d491cf64189a5975cfeb5d68761",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Interactive plot! Play with the variables!\n",
    "vDiff_ab = np.sort(data.vDiff_ab.unique())\n",
    "pyddm.plot.model_gui_jupyter(model=model_ci, conditions={\"vDiff_ab\":vDiff_ab.tolist()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: Condition Invariant.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data[data[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_ci = fit_adjust_model(sample=ddm_data, model=model_ci,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_ci)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_ci_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_ci))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract parameters and BIC for the model objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>197.614476</td>\n",
       "      <td>0.051440</td>\n",
       "      <td>0.354061</td>\n",
       "      <td>-0.099547</td>\n",
       "      <td>0.094187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>208.050035</td>\n",
       "      <td>0.016715</td>\n",
       "      <td>0.421540</td>\n",
       "      <td>0.176852</td>\n",
       "      <td>0.092509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>235.378416</td>\n",
       "      <td>0.006016</td>\n",
       "      <td>0.400642</td>\n",
       "      <td>0.314949</td>\n",
       "      <td>0.094061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>202.590692</td>\n",
       "      <td>0.029411</td>\n",
       "      <td>0.256057</td>\n",
       "      <td>0.017144</td>\n",
       "      <td>0.099571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>244.179249</td>\n",
       "      <td>0.009191</td>\n",
       "      <td>0.432866</td>\n",
       "      <td>-0.149773</td>\n",
       "      <td>0.086832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>199.171074</td>\n",
       "      <td>0.040756</td>\n",
       "      <td>0.532894</td>\n",
       "      <td>-0.050570</td>\n",
       "      <td>0.090629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>227.957362</td>\n",
       "      <td>0.024584</td>\n",
       "      <td>0.652739</td>\n",
       "      <td>0.332271</td>\n",
       "      <td>0.001509</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>200.435388</td>\n",
       "      <td>0.017127</td>\n",
       "      <td>0.359543</td>\n",
       "      <td>-0.001355</td>\n",
       "      <td>0.095878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>223.651085</td>\n",
       "      <td>0.034586</td>\n",
       "      <td>0.370095</td>\n",
       "      <td>-0.204548</td>\n",
       "      <td>0.080100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>198.422078</td>\n",
       "      <td>0.009952</td>\n",
       "      <td>0.267747</td>\n",
       "      <td>0.044239</td>\n",
       "      <td>0.084693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>214.030271</td>\n",
       "      <td>0.015118</td>\n",
       "      <td>0.528341</td>\n",
       "      <td>-0.080456</td>\n",
       "      <td>0.090477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>193.729171</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>0.468458</td>\n",
       "      <td>0.107686</td>\n",
       "      <td>0.097192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>200.076947</td>\n",
       "      <td>0.039294</td>\n",
       "      <td>0.457229</td>\n",
       "      <td>-0.125465</td>\n",
       "      <td>0.098153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>176.304062</td>\n",
       "      <td>0.020042</td>\n",
       "      <td>0.335201</td>\n",
       "      <td>0.106155</td>\n",
       "      <td>0.092399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>171.513208</td>\n",
       "      <td>0.046134</td>\n",
       "      <td>0.312950</td>\n",
       "      <td>-0.041360</td>\n",
       "      <td>0.091495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>205.735467</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.425349</td>\n",
       "      <td>-0.165756</td>\n",
       "      <td>0.094159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>191.076182</td>\n",
       "      <td>0.022450</td>\n",
       "      <td>0.296072</td>\n",
       "      <td>-0.146101</td>\n",
       "      <td>0.096476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>171.106183</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.189458</td>\n",
       "      <td>0.154533</td>\n",
       "      <td>0.083626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>240.941013</td>\n",
       "      <td>0.011753</td>\n",
       "      <td>0.392511</td>\n",
       "      <td>-0.211138</td>\n",
       "      <td>0.097398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>209.104485</td>\n",
       "      <td>0.046922</td>\n",
       "      <td>0.355877</td>\n",
       "      <td>-0.304176</td>\n",
       "      <td>0.096532</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>190.496768</td>\n",
       "      <td>0.030456</td>\n",
       "      <td>0.386742</td>\n",
       "      <td>-0.160806</td>\n",
       "      <td>0.099985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>194.267732</td>\n",
       "      <td>0.037052</td>\n",
       "      <td>0.512639</td>\n",
       "      <td>0.145172</td>\n",
       "      <td>0.097944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>198.016259</td>\n",
       "      <td>0.035278</td>\n",
       "      <td>0.349514</td>\n",
       "      <td>-0.052980</td>\n",
       "      <td>0.099983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>132.169092</td>\n",
       "      <td>0.037773</td>\n",
       "      <td>0.634106</td>\n",
       "      <td>-0.253628</td>\n",
       "      <td>0.095128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>200.937449</td>\n",
       "      <td>0.046573</td>\n",
       "      <td>0.537331</td>\n",
       "      <td>-0.200286</td>\n",
       "      <td>0.095763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>228.597296</td>\n",
       "      <td>0.005602</td>\n",
       "      <td>0.257335</td>\n",
       "      <td>0.558280</td>\n",
       "      <td>0.099234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>195.927336</td>\n",
       "      <td>0.022919</td>\n",
       "      <td>0.617403</td>\n",
       "      <td>0.108030</td>\n",
       "      <td>0.098100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>219.793169</td>\n",
       "      <td>0.017072</td>\n",
       "      <td>0.334385</td>\n",
       "      <td>-0.108161</td>\n",
       "      <td>0.083379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>199.339988</td>\n",
       "      <td>0.017805</td>\n",
       "      <td>0.396239</td>\n",
       "      <td>-0.196035</td>\n",
       "      <td>0.077419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>219.042388</td>\n",
       "      <td>0.019305</td>\n",
       "      <td>0.408597</td>\n",
       "      <td>-0.093732</td>\n",
       "      <td>0.057553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>163.085246</td>\n",
       "      <td>0.036026</td>\n",
       "      <td>0.288635</td>\n",
       "      <td>0.267479</td>\n",
       "      <td>0.050580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>168.522897</td>\n",
       "      <td>0.047802</td>\n",
       "      <td>0.304181</td>\n",
       "      <td>0.153476</td>\n",
       "      <td>0.090843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>209.843890</td>\n",
       "      <td>0.012194</td>\n",
       "      <td>0.298346</td>\n",
       "      <td>0.122056</td>\n",
       "      <td>0.071223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>191.214630</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.447725</td>\n",
       "      <td>-0.107573</td>\n",
       "      <td>0.091328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>152.707693</td>\n",
       "      <td>0.016912</td>\n",
       "      <td>0.378048</td>\n",
       "      <td>-0.062594</td>\n",
       "      <td>0.069296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>220.125024</td>\n",
       "      <td>0.038672</td>\n",
       "      <td>0.442751</td>\n",
       "      <td>-0.293621</td>\n",
       "      <td>0.082915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>161.138775</td>\n",
       "      <td>0.087649</td>\n",
       "      <td>0.515378</td>\n",
       "      <td>-0.043320</td>\n",
       "      <td>0.099337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>196.778289</td>\n",
       "      <td>0.022180</td>\n",
       "      <td>0.406354</td>\n",
       "      <td>-0.044110</td>\n",
       "      <td>0.094491</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0   197.614476  0.051440  0.354061 -0.099547  0.094187\n",
       "1   208.050035  0.016715  0.421540  0.176852  0.092509\n",
       "2   235.378416  0.006016  0.400642  0.314949  0.094061\n",
       "3   202.590692  0.029411  0.256057  0.017144  0.099571\n",
       "4   244.179249  0.009191  0.432866 -0.149773  0.086832\n",
       "5   199.171074  0.040756  0.532894 -0.050570  0.090629\n",
       "6   227.957362  0.024584  0.652739  0.332271  0.001509\n",
       "7   200.435388  0.017127  0.359543 -0.001355  0.095878\n",
       "8   223.651085  0.034586  0.370095 -0.204548  0.080100\n",
       "9   198.422078  0.009952  0.267747  0.044239  0.084693\n",
       "10  214.030271  0.015118  0.528341 -0.080456  0.090477\n",
       "11  193.729171  0.042225  0.468458  0.107686  0.097192\n",
       "12  200.076947  0.039294  0.457229 -0.125465  0.098153\n",
       "13  176.304062  0.020042  0.335201  0.106155  0.092399\n",
       "14  171.513208  0.046134  0.312950 -0.041360  0.091495\n",
       "15  205.735467  0.021013  0.425349 -0.165756  0.094159\n",
       "16  191.076182  0.022450  0.296072 -0.146101  0.096476\n",
       "17  171.106183  0.008381  0.189458  0.154533  0.083626\n",
       "18  240.941013  0.011753  0.392511 -0.211138  0.097398\n",
       "19  209.104485  0.046922  0.355877 -0.304176  0.096532\n",
       "20  190.496768  0.030456  0.386742 -0.160806  0.099985\n",
       "21  194.267732  0.037052  0.512639  0.145172  0.097944\n",
       "22  198.016259  0.035278  0.349514 -0.052980  0.099983\n",
       "23  132.169092  0.037773  0.634106 -0.253628  0.095128\n",
       "24  200.937449  0.046573  0.537331 -0.200286  0.095763\n",
       "25  228.597296  0.005602  0.257335  0.558280  0.099234\n",
       "26  195.927336  0.022919  0.617403  0.108030  0.098100\n",
       "27  219.793169  0.017072  0.334385 -0.108161  0.083379\n",
       "28  199.339988  0.017805  0.396239 -0.196035  0.077419\n",
       "29  219.042388  0.019305  0.408597 -0.093732  0.057553\n",
       "30  163.085246  0.036026  0.288635  0.267479  0.050580\n",
       "31  168.522897  0.047802  0.304181  0.153476  0.090843\n",
       "32  209.843890  0.012194  0.298346  0.122056  0.071223\n",
       "33  191.214630  0.021982  0.447725 -0.107573  0.091328\n",
       "34  152.707693  0.016912  0.378048 -0.062594  0.069296\n",
       "35  220.125024  0.038672  0.442751 -0.293621  0.082915\n",
       "36  161.138775  0.087649  0.515378 -0.043320  0.099337\n",
       "37  196.778289  0.022180  0.406354 -0.044110  0.094491"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_ci_bic = []\n",
    "model_ci_drift = []\n",
    "model_ci_noise = []\n",
    "model_ci_bias = []\n",
    "model_ci_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_ci_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_ci_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_ci_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_ci_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_ci_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_ci_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_ci_bic, \"drift\":model_ci_drift, \"noise\":model_ci_noise, \"bias\":model_ci_bias, \"ndt\":model_ci_ndt}\n",
    "indiv_model_ci = pd.DataFrame(data=d)\n",
    "indiv_model_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means of BIC and Estimates\n",
    "\n",
    "Confidence intervals assume normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>198.765020</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.403298</td>\n",
       "      <td>-0.015494</td>\n",
       "      <td>0.087168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>3.945812</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.017497</td>\n",
       "      <td>0.030632</td>\n",
       "      <td>0.002967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>191.031228</td>\n",
       "      <td>0.022801</td>\n",
       "      <td>0.369004</td>\n",
       "      <td>-0.075533</td>\n",
       "      <td>0.081353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>206.498812</td>\n",
       "      <td>0.033323</td>\n",
       "      <td>0.437593</td>\n",
       "      <td>0.044545</td>\n",
       "      <td>0.092983</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean      198.765020  0.028062  0.403298 -0.015494  0.087168\n",
       "se          3.945812  0.002684  0.017497  0.030632  0.002967\n",
       "ci_lower  191.031228  0.022801  0.369004 -0.075533  0.081353\n",
       "ci_upper  206.498812  0.033323  0.437593  0.044545  0.092983"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_ci = pd.DataFrame(data={\"mean\":indiv_model_ci.mean(), \n",
    "                                        \"se\":indiv_model_ci.sem(),\n",
    "                                        \"ci_lower\":indiv_model_ci.mean()-1.96*indiv_model_ci.sem(),\n",
    "                                        \"ci_upper\":indiv_model_ci.mean()+1.96*indiv_model_ci.sem()}).T\n",
    "summstats_model_ci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DDM: Separately by Block (p,r)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate datasets by type (AB or ApBp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject  trial type     rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
      "0  9156374      1   AB  5.968  0.5  0.3     -2.25          0  30  32.25   \n",
      "1  9156374      2   AB  3.920  0.5  0.3      3.75          1  30  26.25   \n",
      "\n",
      "   choice_lr   H  \n",
      "0          0  75  \n",
      "1          1  35  \n",
      "   subject  trial type     rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
      "0  9156374      1   AB  5.968  0.5  0.3     -2.25          0  30  32.25   \n",
      "1  9156374      2   AB  3.920  0.5  0.3      3.75          1  30  26.25   \n",
      "\n",
      "   choice_lr   H  \n",
      "0          0  75  \n",
      "1          1  35  \n"
     ]
    }
   ],
   "source": [
    "data_ab = data[data.type==\"AB\"]\n",
    "data_apbp = data[data.type==\"ApBp\"]\n",
    "\n",
    "print(data_ab.head(2))\n",
    "print(data_ab.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DDM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a drift subclass so drift can vary with stimulus.\n",
    "class DriftRate(ddm.models.Drift):\n",
    "  name = \"Drift depends linearly on value difference\"\n",
    "  required_parameters = [\"driftrate\"] # Parameters we want to include in the model.\n",
    "  required_conditions = [\"vDiff_ab\"] # The column in your sample data that modulates the parameters above.\n",
    "  def get_drift(self, conditions, **kwargs):\n",
    "    return self.driftrate * conditions[\"vDiff_ab\"]\n",
    "\n",
    "# Define the model.\n",
    "model_ab = Model(name=\"Standard DDM fit to AB choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))\n",
    "\n",
    "model_apbp = Model(name=\"Standard DDM fit to ApBp choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: AB.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data_ab.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data_ab[data_ab[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_ab = fit_adjust_model(sample=ddm_data, model=model_ab,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_ab)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_ab_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_ab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: ApBp.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data_apbp.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data_apbp[data_apbp[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_apbp = fit_adjust_model(sample=ddm_data, model=model_apbp,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_apbp)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_apbp_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_apbp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract estimates and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>97.312660</td>\n",
       "      <td>0.058783</td>\n",
       "      <td>0.313904</td>\n",
       "      <td>-0.165942</td>\n",
       "      <td>0.067146</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>106.887612</td>\n",
       "      <td>0.018007</td>\n",
       "      <td>0.401901</td>\n",
       "      <td>0.201850</td>\n",
       "      <td>0.098725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>116.778228</td>\n",
       "      <td>0.012515</td>\n",
       "      <td>0.301361</td>\n",
       "      <td>0.250897</td>\n",
       "      <td>0.074616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.909972</td>\n",
       "      <td>0.031255</td>\n",
       "      <td>0.245422</td>\n",
       "      <td>0.106721</td>\n",
       "      <td>0.078875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>125.130558</td>\n",
       "      <td>0.001427</td>\n",
       "      <td>0.392878</td>\n",
       "      <td>-0.324815</td>\n",
       "      <td>0.092661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>95.995432</td>\n",
       "      <td>0.058460</td>\n",
       "      <td>0.561719</td>\n",
       "      <td>-0.104660</td>\n",
       "      <td>0.080221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>123.185262</td>\n",
       "      <td>0.019538</td>\n",
       "      <td>0.542202</td>\n",
       "      <td>0.369781</td>\n",
       "      <td>0.004400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>102.620662</td>\n",
       "      <td>0.015448</td>\n",
       "      <td>0.283405</td>\n",
       "      <td>-0.248277</td>\n",
       "      <td>0.098520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>118.132514</td>\n",
       "      <td>0.033262</td>\n",
       "      <td>0.364450</td>\n",
       "      <td>-0.158731</td>\n",
       "      <td>0.081542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>101.682048</td>\n",
       "      <td>0.011473</td>\n",
       "      <td>0.310702</td>\n",
       "      <td>0.026457</td>\n",
       "      <td>0.093707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>124.760575</td>\n",
       "      <td>0.005953</td>\n",
       "      <td>0.475622</td>\n",
       "      <td>-0.136992</td>\n",
       "      <td>0.061149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>98.556269</td>\n",
       "      <td>0.040310</td>\n",
       "      <td>0.471072</td>\n",
       "      <td>0.139960</td>\n",
       "      <td>0.093565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>90.518219</td>\n",
       "      <td>0.043119</td>\n",
       "      <td>0.462004</td>\n",
       "      <td>-0.110851</td>\n",
       "      <td>0.095099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>101.160660</td>\n",
       "      <td>0.016877</td>\n",
       "      <td>0.344502</td>\n",
       "      <td>0.151642</td>\n",
       "      <td>0.098547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>73.356560</td>\n",
       "      <td>0.062568</td>\n",
       "      <td>0.335889</td>\n",
       "      <td>-0.020023</td>\n",
       "      <td>0.093246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105.262644</td>\n",
       "      <td>0.018110</td>\n",
       "      <td>0.440289</td>\n",
       "      <td>-0.284254</td>\n",
       "      <td>0.090971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>104.601163</td>\n",
       "      <td>0.022456</td>\n",
       "      <td>0.307022</td>\n",
       "      <td>-0.235243</td>\n",
       "      <td>0.091167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>101.472044</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>0.198710</td>\n",
       "      <td>0.088326</td>\n",
       "      <td>0.085752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>132.299287</td>\n",
       "      <td>0.006200</td>\n",
       "      <td>0.423419</td>\n",
       "      <td>-0.084560</td>\n",
       "      <td>0.098117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>107.621036</td>\n",
       "      <td>0.048304</td>\n",
       "      <td>0.308802</td>\n",
       "      <td>-0.454185</td>\n",
       "      <td>0.097837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>99.626387</td>\n",
       "      <td>0.028542</td>\n",
       "      <td>0.428676</td>\n",
       "      <td>-0.079358</td>\n",
       "      <td>0.096616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>98.451954</td>\n",
       "      <td>0.057009</td>\n",
       "      <td>0.475276</td>\n",
       "      <td>-0.002364</td>\n",
       "      <td>0.090607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>95.896772</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.351311</td>\n",
       "      <td>-0.021840</td>\n",
       "      <td>0.080476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>73.579986</td>\n",
       "      <td>0.034267</td>\n",
       "      <td>0.493990</td>\n",
       "      <td>-0.404989</td>\n",
       "      <td>0.099325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>111.710060</td>\n",
       "      <td>0.024615</td>\n",
       "      <td>0.534558</td>\n",
       "      <td>-0.083470</td>\n",
       "      <td>0.093187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>129.320311</td>\n",
       "      <td>0.004740</td>\n",
       "      <td>0.209897</td>\n",
       "      <td>0.589860</td>\n",
       "      <td>0.055519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>91.650160</td>\n",
       "      <td>0.009659</td>\n",
       "      <td>0.581443</td>\n",
       "      <td>0.352125</td>\n",
       "      <td>0.094003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>111.821562</td>\n",
       "      <td>0.018684</td>\n",
       "      <td>0.361402</td>\n",
       "      <td>-0.135620</td>\n",
       "      <td>0.065338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>101.224173</td>\n",
       "      <td>0.020581</td>\n",
       "      <td>0.382945</td>\n",
       "      <td>-0.355394</td>\n",
       "      <td>0.094269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>118.948819</td>\n",
       "      <td>0.016342</td>\n",
       "      <td>0.380204</td>\n",
       "      <td>-0.008548</td>\n",
       "      <td>0.073059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>93.557402</td>\n",
       "      <td>0.027236</td>\n",
       "      <td>0.255575</td>\n",
       "      <td>0.320105</td>\n",
       "      <td>0.095643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>89.608001</td>\n",
       "      <td>0.047337</td>\n",
       "      <td>0.293538</td>\n",
       "      <td>0.146374</td>\n",
       "      <td>0.097945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>94.062152</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.260023</td>\n",
       "      <td>0.109291</td>\n",
       "      <td>0.081706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>104.596994</td>\n",
       "      <td>0.023810</td>\n",
       "      <td>0.400749</td>\n",
       "      <td>-0.261369</td>\n",
       "      <td>0.082734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>82.809513</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.385072</td>\n",
       "      <td>-0.125238</td>\n",
       "      <td>0.073957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>104.701719</td>\n",
       "      <td>0.053920</td>\n",
       "      <td>0.452571</td>\n",
       "      <td>-0.387631</td>\n",
       "      <td>0.098328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>67.932550</td>\n",
       "      <td>0.106446</td>\n",
       "      <td>0.364090</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.090347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>112.295631</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>0.405943</td>\n",
       "      <td>-0.146260</td>\n",
       "      <td>0.081574</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0    97.312660  0.058783  0.313904 -0.165942  0.067146\n",
       "1   106.887612  0.018007  0.401901  0.201850  0.098725\n",
       "2   116.778228  0.012515  0.301361  0.250897  0.074616\n",
       "3   104.909972  0.031255  0.245422  0.106721  0.078875\n",
       "4   125.130558  0.001427  0.392878 -0.324815  0.092661\n",
       "5    95.995432  0.058460  0.561719 -0.104660  0.080221\n",
       "6   123.185262  0.019538  0.542202  0.369781  0.004400\n",
       "7   102.620662  0.015448  0.283405 -0.248277  0.098520\n",
       "8   118.132514  0.033262  0.364450 -0.158731  0.081542\n",
       "9   101.682048  0.011473  0.310702  0.026457  0.093707\n",
       "10  124.760575  0.005953  0.475622 -0.136992  0.061149\n",
       "11   98.556269  0.040310  0.471072  0.139960  0.093565\n",
       "12   90.518219  0.043119  0.462004 -0.110851  0.095099\n",
       "13  101.160660  0.016877  0.344502  0.151642  0.098547\n",
       "14   73.356560  0.062568  0.335889 -0.020023  0.093246\n",
       "15  105.262644  0.018110  0.440289 -0.284254  0.090971\n",
       "16  104.601163  0.022456  0.307022 -0.235243  0.091167\n",
       "17  101.472044  0.009334  0.198710  0.088326  0.085752\n",
       "18  132.299287  0.006200  0.423419 -0.084560  0.098117\n",
       "19  107.621036  0.048304  0.308802 -0.454185  0.097837\n",
       "20   99.626387  0.028542  0.428676 -0.079358  0.096616\n",
       "21   98.451954  0.057009  0.475276 -0.002364  0.090607\n",
       "22   95.896772  0.042200  0.351311 -0.021840  0.080476\n",
       "23   73.579986  0.034267  0.493990 -0.404989  0.099325\n",
       "24  111.710060  0.024615  0.534558 -0.083470  0.093187\n",
       "25  129.320311  0.004740  0.209897  0.589860  0.055519\n",
       "26   91.650160  0.009659  0.581443  0.352125  0.094003\n",
       "27  111.821562  0.018684  0.361402 -0.135620  0.065338\n",
       "28  101.224173  0.020581  0.382945 -0.355394  0.094269\n",
       "29  118.948819  0.016342  0.380204 -0.008548  0.073059\n",
       "30   93.557402  0.027236  0.255575  0.320105  0.095643\n",
       "31   89.608001  0.047337  0.293538  0.146374  0.097945\n",
       "32   94.062152  0.015743  0.260023  0.109291  0.081706\n",
       "33  104.596994  0.023810  0.400749 -0.261369  0.082734\n",
       "34   82.809513  0.014270  0.385072 -0.125238  0.073957\n",
       "35  104.701719  0.053920  0.452571 -0.387631  0.098328\n",
       "36   67.932550  0.106446  0.364090  0.092803  0.090347\n",
       "37  112.295631  0.017212  0.405943 -0.146260  0.081574"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_ab_bic = []\n",
    "model_ab_drift = []\n",
    "model_ab_noise = []\n",
    "model_ab_bias = []\n",
    "model_ab_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data_ab.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_ab_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_ab_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_ab_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_ab_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_ab_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_ab_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_ab_bic, \"drift\":model_ab_drift, \"noise\":model_ab_noise, \"bias\":model_ab_bias, \"ndt\":model_ab_ndt}\n",
    "indiv_model_ab = pd.DataFrame(data=d)\n",
    "indiv_model_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>108.010532</td>\n",
       "      <td>0.045312</td>\n",
       "      <td>0.367774</td>\n",
       "      <td>-0.048118</td>\n",
       "      <td>0.099541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>110.054843</td>\n",
       "      <td>0.015322</td>\n",
       "      <td>0.435725</td>\n",
       "      <td>0.178335</td>\n",
       "      <td>0.098093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.858334</td>\n",
       "      <td>-0.001279</td>\n",
       "      <td>0.421583</td>\n",
       "      <td>0.340519</td>\n",
       "      <td>0.090151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.605127</td>\n",
       "      <td>0.028349</td>\n",
       "      <td>0.268849</td>\n",
       "      <td>0.009511</td>\n",
       "      <td>0.092376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102.642345</td>\n",
       "      <td>0.028829</td>\n",
       "      <td>0.334906</td>\n",
       "      <td>-0.265369</td>\n",
       "      <td>0.063802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>110.163505</td>\n",
       "      <td>0.037922</td>\n",
       "      <td>0.498142</td>\n",
       "      <td>-0.183972</td>\n",
       "      <td>0.097209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>102.625238</td>\n",
       "      <td>0.038103</td>\n",
       "      <td>0.794343</td>\n",
       "      <td>0.291533</td>\n",
       "      <td>0.006331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>95.909183</td>\n",
       "      <td>0.020517</td>\n",
       "      <td>0.325959</td>\n",
       "      <td>0.242095</td>\n",
       "      <td>0.093054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>114.542292</td>\n",
       "      <td>0.036054</td>\n",
       "      <td>0.372955</td>\n",
       "      <td>-0.259397</td>\n",
       "      <td>0.087277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>99.339464</td>\n",
       "      <td>0.009057</td>\n",
       "      <td>0.188688</td>\n",
       "      <td>0.130763</td>\n",
       "      <td>0.090501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>83.484650</td>\n",
       "      <td>0.046020</td>\n",
       "      <td>0.531531</td>\n",
       "      <td>-0.251401</td>\n",
       "      <td>0.091931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>104.248719</td>\n",
       "      <td>0.043093</td>\n",
       "      <td>0.461655</td>\n",
       "      <td>0.066254</td>\n",
       "      <td>0.063072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>118.104911</td>\n",
       "      <td>0.038434</td>\n",
       "      <td>0.453281</td>\n",
       "      <td>-0.177244</td>\n",
       "      <td>0.091398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>79.555206</td>\n",
       "      <td>0.024540</td>\n",
       "      <td>0.287114</td>\n",
       "      <td>0.090258</td>\n",
       "      <td>0.096028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>101.188043</td>\n",
       "      <td>0.038005</td>\n",
       "      <td>0.262878</td>\n",
       "      <td>-0.008755</td>\n",
       "      <td>0.095092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>105.787908</td>\n",
       "      <td>0.024836</td>\n",
       "      <td>0.375258</td>\n",
       "      <td>-0.084398</td>\n",
       "      <td>0.072452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>93.135429</td>\n",
       "      <td>0.022273</td>\n",
       "      <td>0.261362</td>\n",
       "      <td>-0.030723</td>\n",
       "      <td>0.094408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>74.499192</td>\n",
       "      <td>0.007255</td>\n",
       "      <td>0.156495</td>\n",
       "      <td>0.196292</td>\n",
       "      <td>0.091142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>112.093729</td>\n",
       "      <td>0.018390</td>\n",
       "      <td>0.333041</td>\n",
       "      <td>-0.402379</td>\n",
       "      <td>0.095789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>107.613960</td>\n",
       "      <td>0.049958</td>\n",
       "      <td>0.380869</td>\n",
       "      <td>-0.257850</td>\n",
       "      <td>0.091944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>98.249253</td>\n",
       "      <td>0.033565</td>\n",
       "      <td>0.346251</td>\n",
       "      <td>-0.147640</td>\n",
       "      <td>0.096733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>99.170374</td>\n",
       "      <td>0.011612</td>\n",
       "      <td>0.350321</td>\n",
       "      <td>0.506836</td>\n",
       "      <td>0.092958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>109.568620</td>\n",
       "      <td>0.030223</td>\n",
       "      <td>0.340185</td>\n",
       "      <td>-0.051842</td>\n",
       "      <td>0.081181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>64.342608</td>\n",
       "      <td>0.047283</td>\n",
       "      <td>0.695531</td>\n",
       "      <td>-0.274347</td>\n",
       "      <td>0.092958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>94.861249</td>\n",
       "      <td>0.074649</td>\n",
       "      <td>0.517400</td>\n",
       "      <td>-0.301158</td>\n",
       "      <td>0.099852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>107.671604</td>\n",
       "      <td>0.005534</td>\n",
       "      <td>0.253579</td>\n",
       "      <td>0.614527</td>\n",
       "      <td>0.097336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>101.747841</td>\n",
       "      <td>0.033422</td>\n",
       "      <td>0.526874</td>\n",
       "      <td>-0.180712</td>\n",
       "      <td>0.094292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>115.195368</td>\n",
       "      <td>0.015243</td>\n",
       "      <td>0.295262</td>\n",
       "      <td>-0.013883</td>\n",
       "      <td>0.091952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>103.047073</td>\n",
       "      <td>0.014977</td>\n",
       "      <td>0.380055</td>\n",
       "      <td>-0.007112</td>\n",
       "      <td>0.092916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>106.462909</td>\n",
       "      <td>0.022449</td>\n",
       "      <td>0.419932</td>\n",
       "      <td>-0.137426</td>\n",
       "      <td>0.000924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>74.013216</td>\n",
       "      <td>0.045885</td>\n",
       "      <td>0.261789</td>\n",
       "      <td>0.319417</td>\n",
       "      <td>0.086589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>87.996129</td>\n",
       "      <td>0.047792</td>\n",
       "      <td>0.312919</td>\n",
       "      <td>0.125886</td>\n",
       "      <td>0.088701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>119.964475</td>\n",
       "      <td>0.009745</td>\n",
       "      <td>0.303642</td>\n",
       "      <td>0.161767</td>\n",
       "      <td>0.098622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>93.470049</td>\n",
       "      <td>0.023131</td>\n",
       "      <td>0.491380</td>\n",
       "      <td>-0.095740</td>\n",
       "      <td>0.098887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>74.842579</td>\n",
       "      <td>0.018388</td>\n",
       "      <td>0.329313</td>\n",
       "      <td>0.094917</td>\n",
       "      <td>0.076799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>122.449480</td>\n",
       "      <td>0.032294</td>\n",
       "      <td>0.418181</td>\n",
       "      <td>-0.281708</td>\n",
       "      <td>0.091546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>93.770097</td>\n",
       "      <td>0.073291</td>\n",
       "      <td>0.559815</td>\n",
       "      <td>-0.096834</td>\n",
       "      <td>0.075396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>85.550257</td>\n",
       "      <td>0.031772</td>\n",
       "      <td>0.346805</td>\n",
       "      <td>0.094368</td>\n",
       "      <td>0.087666</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0   108.010532  0.045312  0.367774 -0.048118  0.099541\n",
       "1   110.054843  0.015322  0.435725  0.178335  0.098093\n",
       "2   110.858334 -0.001279  0.421583  0.340519  0.090151\n",
       "3   106.605127  0.028349  0.268849  0.009511  0.092376\n",
       "4   102.642345  0.028829  0.334906 -0.265369  0.063802\n",
       "5   110.163505  0.037922  0.498142 -0.183972  0.097209\n",
       "6   102.625238  0.038103  0.794343  0.291533  0.006331\n",
       "7    95.909183  0.020517  0.325959  0.242095  0.093054\n",
       "8   114.542292  0.036054  0.372955 -0.259397  0.087277\n",
       "9    99.339464  0.009057  0.188688  0.130763  0.090501\n",
       "10   83.484650  0.046020  0.531531 -0.251401  0.091931\n",
       "11  104.248719  0.043093  0.461655  0.066254  0.063072\n",
       "12  118.104911  0.038434  0.453281 -0.177244  0.091398\n",
       "13   79.555206  0.024540  0.287114  0.090258  0.096028\n",
       "14  101.188043  0.038005  0.262878 -0.008755  0.095092\n",
       "15  105.787908  0.024836  0.375258 -0.084398  0.072452\n",
       "16   93.135429  0.022273  0.261362 -0.030723  0.094408\n",
       "17   74.499192  0.007255  0.156495  0.196292  0.091142\n",
       "18  112.093729  0.018390  0.333041 -0.402379  0.095789\n",
       "19  107.613960  0.049958  0.380869 -0.257850  0.091944\n",
       "20   98.249253  0.033565  0.346251 -0.147640  0.096733\n",
       "21   99.170374  0.011612  0.350321  0.506836  0.092958\n",
       "22  109.568620  0.030223  0.340185 -0.051842  0.081181\n",
       "23   64.342608  0.047283  0.695531 -0.274347  0.092958\n",
       "24   94.861249  0.074649  0.517400 -0.301158  0.099852\n",
       "25  107.671604  0.005534  0.253579  0.614527  0.097336\n",
       "26  101.747841  0.033422  0.526874 -0.180712  0.094292\n",
       "27  115.195368  0.015243  0.295262 -0.013883  0.091952\n",
       "28  103.047073  0.014977  0.380055 -0.007112  0.092916\n",
       "29  106.462909  0.022449  0.419932 -0.137426  0.000924\n",
       "30   74.013216  0.045885  0.261789  0.319417  0.086589\n",
       "31   87.996129  0.047792  0.312919  0.125886  0.088701\n",
       "32  119.964475  0.009745  0.303642  0.161767  0.098622\n",
       "33   93.470049  0.023131  0.491380 -0.095740  0.098887\n",
       "34   74.842579  0.018388  0.329313  0.094917  0.076799\n",
       "35  122.449480  0.032294  0.418181 -0.281708  0.091546\n",
       "36   93.770097  0.073291  0.559815 -0.096834  0.075396\n",
       "37   85.550257  0.031772  0.346805  0.094368  0.087666"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_apbp_bic = []\n",
    "model_apbp_drift = []\n",
    "model_apbp_noise = []\n",
    "model_apbp_bias = []\n",
    "model_apbp_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data_apbp.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_apbp_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_apbp_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_apbp_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_apbp_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_apbp_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_apbp_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_apbp_bic, \"drift\":model_apbp_drift, \"noise\":model_apbp_noise, \"bias\":model_apbp_bias, \"ndt\":model_apbp_ndt}\n",
    "indiv_model_apbp = pd.DataFrame(data=d)\n",
    "indiv_model_apbp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means of Estimates and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>103.000988</td>\n",
       "      <td>0.028842</td>\n",
       "      <td>0.381646</td>\n",
       "      <td>-0.036695</td>\n",
       "      <td>0.084750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>2.399852</td>\n",
       "      <td>0.003468</td>\n",
       "      <td>0.015598</td>\n",
       "      <td>0.038260</td>\n",
       "      <td>0.002868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>98.297278</td>\n",
       "      <td>0.022046</td>\n",
       "      <td>0.351073</td>\n",
       "      <td>-0.111685</td>\n",
       "      <td>0.079128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>107.704698</td>\n",
       "      <td>0.035639</td>\n",
       "      <td>0.412218</td>\n",
       "      <td>0.038295</td>\n",
       "      <td>0.090372</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean      103.000988  0.028842  0.381646 -0.036695  0.084750\n",
       "se          2.399852  0.003468  0.015598  0.038260  0.002868\n",
       "ci_lower   98.297278  0.022046  0.351073 -0.111685  0.079128\n",
       "ci_upper  107.704698  0.035639  0.412218  0.038295  0.090372"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_ab = pd.DataFrame(data={\"mean\":indiv_model_ab.mean(), \n",
    "                                        \"se\":indiv_model_ab.sem(),\n",
    "                                        \"ci_lower\":indiv_model_ab.mean()-1.96*indiv_model_ab.sem(),\n",
    "                                        \"ci_upper\":indiv_model_ab.mean()+1.96*indiv_model_ab.sem()}).T\n",
    "summstats_model_ab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>99.811468</td>\n",
       "      <td>0.030059</td>\n",
       "      <td>0.385833</td>\n",
       "      <td>-0.002493</td>\n",
       "      <td>0.085445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>2.235519</td>\n",
       "      <td>0.002753</td>\n",
       "      <td>0.020820</td>\n",
       "      <td>0.037725</td>\n",
       "      <td>0.003488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>95.429851</td>\n",
       "      <td>0.024664</td>\n",
       "      <td>0.345026</td>\n",
       "      <td>-0.076435</td>\n",
       "      <td>0.078608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>104.193085</td>\n",
       "      <td>0.035454</td>\n",
       "      <td>0.426639</td>\n",
       "      <td>0.071449</td>\n",
       "      <td>0.092282</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean       99.811468  0.030059  0.385833 -0.002493  0.085445\n",
       "se          2.235519  0.002753  0.020820  0.037725  0.003488\n",
       "ci_lower   95.429851  0.024664  0.345026 -0.076435  0.078608\n",
       "ci_upper  104.193085  0.035454  0.426639  0.071449  0.092282"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_apbp = pd.DataFrame(data={\"mean\":indiv_model_apbp.mean(), \n",
    "                                        \"se\":indiv_model_apbp.sem(),\n",
    "                                        \"ci_lower\":indiv_model_apbp.mean()-1.96*indiv_model_apbp.sem(),\n",
    "                                        \"ci_upper\":indiv_model_apbp.mean()+1.96*indiv_model_apbp.sem()}).T\n",
    "summstats_model_apbp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_diff = indiv_model_apbp.noise - indiv_model_ab.noise\n",
    "plt.hist(est_diff)\n",
    "plt.plot((0, 0), (0, 9), scaley = False)\n",
    "plt.xlabel(\"Noise ApBp - Noise AB\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# DDM: by H"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Separate dataset by H"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   subject  trial type     rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
      "0  9156374      1   AB  5.968  0.5  0.3     -2.25          0  30  32.25   \n",
      "3  9156374      4   AB  4.630  0.5  0.3      0.75          0  30  29.25   \n",
      "\n",
      "   choice_lr   H  \n",
      "0          0  75  \n",
      "3          1  55  \n",
      "   subject  trial type     rt    p    r  vDiff_ab  choice_ab  vA     vB  \\\n",
      "1  9156374      2   AB  3.920  0.5  0.3      3.75          1  30  26.25   \n",
      "2  9156374      3   AB  4.045  0.5  0.3      5.25          1  30  24.75   \n",
      "\n",
      "   choice_lr   H  \n",
      "1          1  35  \n",
      "2          1  25  \n"
     ]
    }
   ],
   "source": [
    "data_HH = data[data.H>50]\n",
    "data_HL = data[data.H<=50]\n",
    "\n",
    "print(data_HH.head(2))\n",
    "print(data_HL.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate DDM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a drift subclass so drift can vary with stimulus.\n",
    "class DriftRate(ddm.models.Drift):\n",
    "  name = \"Drift depends linearly on value difference\"\n",
    "  required_parameters = [\"driftrate\"] # Parameters we want to include in the model.\n",
    "  required_conditions = [\"vDiff_ab\"] # The column in your sample data that modulates the parameters above.\n",
    "  def get_drift(self, conditions, **kwargs):\n",
    "    return self.driftrate * conditions[\"vDiff_ab\"]\n",
    "\n",
    "# Define the model.\n",
    "model_HH = Model(name=\"Standard DDM fit to high H choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))\n",
    "\n",
    "model_HL = Model(name=\"Standard DDM fit to low H choices\",\n",
    "                 drift=DriftRate(driftrate=Fittable(minval=-1, maxval=1.5)),\n",
    "                 noise=NoiseConstant(noise=Fittable(minval=.001, maxval=2)),\n",
    "                 bound=BoundConstant(B=1),\n",
    "                 IC=ICPoint(x0=Fittable(minval=-.99, maxval=.99)),\n",
    "                 overlay=OverlayNonDecision(nondectime=Fittable(minval=0, maxval=.1)),\n",
    "                 dx=.01, dt=.01, T_dur=maxRT,  # dx: spatial grid for evidence space (-B to B, in dx bins), dt: time step in s. See Shin et al 2022 Fig 4 for why I set dx=dt.\n",
    "                 choice_names=(\"A\",\"B\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting2:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: High H.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data_HH.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data_HH[data_HH[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_HH = fit_adjust_model(sample=ddm_data, model=model_HH,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_HH)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_HH_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_HH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fitting2:\n",
    "\n",
    "    # Only run this if specified at the start. Otherwise, just load pre-saved weights.\n",
    "    print(\"DDM: Low H.\")\n",
    "\n",
    "    # Iterate through subjects.\n",
    "    subnums = np.sort(data_HL.subject.unique())\n",
    "    for subnum in subnums:\n",
    "\n",
    "        # Progress tracker.\n",
    "        print(\"=========================\")\n",
    "        print(\"Subject \" + str(subnum))\n",
    "\n",
    "        # Subset the data.\n",
    "        subdata = data_HL[data_HL[\"subject\"]==subnum]\n",
    "\n",
    "        # Create a sample object from our data. Sample objects are the standard input for pyDDM fitting functions.\n",
    "        ddm_data = Sample.from_pandas_dataframe(subdata, rt_column_name=\"rt\", choice_column_name=\"choice_ab\", choice_names=(\"A\",\"B\"))\n",
    "\n",
    "        # Fit the model and show it off. Keep track of how long it took to estimate the parameters.\n",
    "        clock = TicToc() # Timer\n",
    "        clock.tic()\n",
    "        set_N_cpus(ncpu) # Parallelize\n",
    "        fit_model_HL = fit_adjust_model(sample=ddm_data, model=model_HL,\n",
    "                                        fitting_method=\"differential_evolution\",\n",
    "                                        lossfunction=LossRobustBIC,\n",
    "                                        verbose=False)\n",
    "        clock.toc(\"Fitting subject \" + str(subnum) + \" took\")\n",
    "        display_model(fit_model_HL)\n",
    "\n",
    "        # Save\n",
    "        filename = ddmdir + \"fit_model_HL_\" + str(subnum) + \".txt\"\n",
    "        with open(filename, \"w\") as f:\n",
    "          f.write(repr(fit_model_HL))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract estimates and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>110.930564</td>\n",
       "      <td>0.059909</td>\n",
       "      <td>0.389504</td>\n",
       "      <td>0.091593</td>\n",
       "      <td>0.099494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>111.755899</td>\n",
       "      <td>0.018927</td>\n",
       "      <td>0.472713</td>\n",
       "      <td>0.285344</td>\n",
       "      <td>0.092635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>129.871152</td>\n",
       "      <td>0.002744</td>\n",
       "      <td>0.432578</td>\n",
       "      <td>0.184391</td>\n",
       "      <td>0.098651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>89.757980</td>\n",
       "      <td>0.029984</td>\n",
       "      <td>0.201748</td>\n",
       "      <td>0.166805</td>\n",
       "      <td>0.088989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>134.607987</td>\n",
       "      <td>-0.000856</td>\n",
       "      <td>0.427275</td>\n",
       "      <td>-0.176999</td>\n",
       "      <td>0.086487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>108.767646</td>\n",
       "      <td>0.024546</td>\n",
       "      <td>0.582823</td>\n",
       "      <td>0.008242</td>\n",
       "      <td>0.092895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>122.051411</td>\n",
       "      <td>0.018651</td>\n",
       "      <td>0.618892</td>\n",
       "      <td>0.205449</td>\n",
       "      <td>0.009889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>108.492784</td>\n",
       "      <td>0.015912</td>\n",
       "      <td>0.388559</td>\n",
       "      <td>0.055932</td>\n",
       "      <td>0.070187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>120.459692</td>\n",
       "      <td>0.026709</td>\n",
       "      <td>0.368069</td>\n",
       "      <td>-0.223881</td>\n",
       "      <td>0.053266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>92.193540</td>\n",
       "      <td>0.009733</td>\n",
       "      <td>0.241601</td>\n",
       "      <td>0.108181</td>\n",
       "      <td>0.075853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>111.828812</td>\n",
       "      <td>0.021515</td>\n",
       "      <td>0.492906</td>\n",
       "      <td>0.007024</td>\n",
       "      <td>0.036621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>92.734188</td>\n",
       "      <td>0.052248</td>\n",
       "      <td>0.445935</td>\n",
       "      <td>0.230209</td>\n",
       "      <td>0.044159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>114.897839</td>\n",
       "      <td>-0.029013</td>\n",
       "      <td>0.449814</td>\n",
       "      <td>-0.009311</td>\n",
       "      <td>0.051472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>81.048689</td>\n",
       "      <td>0.024391</td>\n",
       "      <td>0.385299</td>\n",
       "      <td>0.325600</td>\n",
       "      <td>0.091970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>89.879978</td>\n",
       "      <td>0.060549</td>\n",
       "      <td>0.329554</td>\n",
       "      <td>0.246923</td>\n",
       "      <td>0.095155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>114.144179</td>\n",
       "      <td>0.012016</td>\n",
       "      <td>0.460151</td>\n",
       "      <td>-0.196376</td>\n",
       "      <td>0.096613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>103.227186</td>\n",
       "      <td>0.021726</td>\n",
       "      <td>0.274099</td>\n",
       "      <td>-0.192162</td>\n",
       "      <td>0.080556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>84.809474</td>\n",
       "      <td>0.009944</td>\n",
       "      <td>0.214785</td>\n",
       "      <td>0.333976</td>\n",
       "      <td>0.098337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>132.460618</td>\n",
       "      <td>-0.004729</td>\n",
       "      <td>0.356449</td>\n",
       "      <td>-0.271819</td>\n",
       "      <td>0.088649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>120.722439</td>\n",
       "      <td>0.064129</td>\n",
       "      <td>0.404446</td>\n",
       "      <td>-0.259390</td>\n",
       "      <td>0.092854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>90.434084</td>\n",
       "      <td>0.027720</td>\n",
       "      <td>0.356612</td>\n",
       "      <td>-0.144761</td>\n",
       "      <td>0.091088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>109.469409</td>\n",
       "      <td>-0.005579</td>\n",
       "      <td>0.535738</td>\n",
       "      <td>0.130116</td>\n",
       "      <td>0.095175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>96.720282</td>\n",
       "      <td>0.016642</td>\n",
       "      <td>0.196443</td>\n",
       "      <td>-0.486145</td>\n",
       "      <td>0.090046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>58.780260</td>\n",
       "      <td>0.065048</td>\n",
       "      <td>0.548725</td>\n",
       "      <td>-0.192892</td>\n",
       "      <td>0.094991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>104.329838</td>\n",
       "      <td>-0.060309</td>\n",
       "      <td>0.435952</td>\n",
       "      <td>-0.204914</td>\n",
       "      <td>0.095352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>113.256847</td>\n",
       "      <td>-0.033569</td>\n",
       "      <td>0.283277</td>\n",
       "      <td>0.320838</td>\n",
       "      <td>0.095785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100.995101</td>\n",
       "      <td>0.017117</td>\n",
       "      <td>0.659542</td>\n",
       "      <td>0.135914</td>\n",
       "      <td>0.090872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>112.526022</td>\n",
       "      <td>0.021746</td>\n",
       "      <td>0.329150</td>\n",
       "      <td>-0.030793</td>\n",
       "      <td>0.097180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>112.581981</td>\n",
       "      <td>0.014279</td>\n",
       "      <td>0.468894</td>\n",
       "      <td>-0.086904</td>\n",
       "      <td>0.098755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>114.519047</td>\n",
       "      <td>0.015638</td>\n",
       "      <td>0.365781</td>\n",
       "      <td>-0.283815</td>\n",
       "      <td>0.094740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>75.913800</td>\n",
       "      <td>0.100824</td>\n",
       "      <td>0.311442</td>\n",
       "      <td>0.156187</td>\n",
       "      <td>0.094485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>73.512892</td>\n",
       "      <td>0.035068</td>\n",
       "      <td>0.211150</td>\n",
       "      <td>-0.153345</td>\n",
       "      <td>0.091626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>100.164544</td>\n",
       "      <td>0.012818</td>\n",
       "      <td>0.312888</td>\n",
       "      <td>0.227823</td>\n",
       "      <td>0.086092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>106.633707</td>\n",
       "      <td>0.030955</td>\n",
       "      <td>0.505708</td>\n",
       "      <td>-0.134451</td>\n",
       "      <td>0.095304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>78.271780</td>\n",
       "      <td>0.006213</td>\n",
       "      <td>0.408556</td>\n",
       "      <td>0.048438</td>\n",
       "      <td>0.094505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>111.083018</td>\n",
       "      <td>-0.064990</td>\n",
       "      <td>0.445026</td>\n",
       "      <td>-0.148549</td>\n",
       "      <td>0.091513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>76.579734</td>\n",
       "      <td>0.144600</td>\n",
       "      <td>0.505266</td>\n",
       "      <td>0.042897</td>\n",
       "      <td>0.090022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>122.726522</td>\n",
       "      <td>0.021658</td>\n",
       "      <td>0.430761</td>\n",
       "      <td>-0.028441</td>\n",
       "      <td>0.065235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0   110.930564  0.059909  0.389504  0.091593  0.099494\n",
       "1   111.755899  0.018927  0.472713  0.285344  0.092635\n",
       "2   129.871152  0.002744  0.432578  0.184391  0.098651\n",
       "3    89.757980  0.029984  0.201748  0.166805  0.088989\n",
       "4   134.607987 -0.000856  0.427275 -0.176999  0.086487\n",
       "5   108.767646  0.024546  0.582823  0.008242  0.092895\n",
       "6   122.051411  0.018651  0.618892  0.205449  0.009889\n",
       "7   108.492784  0.015912  0.388559  0.055932  0.070187\n",
       "8   120.459692  0.026709  0.368069 -0.223881  0.053266\n",
       "9    92.193540  0.009733  0.241601  0.108181  0.075853\n",
       "10  111.828812  0.021515  0.492906  0.007024  0.036621\n",
       "11   92.734188  0.052248  0.445935  0.230209  0.044159\n",
       "12  114.897839 -0.029013  0.449814 -0.009311  0.051472\n",
       "13   81.048689  0.024391  0.385299  0.325600  0.091970\n",
       "14   89.879978  0.060549  0.329554  0.246923  0.095155\n",
       "15  114.144179  0.012016  0.460151 -0.196376  0.096613\n",
       "16  103.227186  0.021726  0.274099 -0.192162  0.080556\n",
       "17   84.809474  0.009944  0.214785  0.333976  0.098337\n",
       "18  132.460618 -0.004729  0.356449 -0.271819  0.088649\n",
       "19  120.722439  0.064129  0.404446 -0.259390  0.092854\n",
       "20   90.434084  0.027720  0.356612 -0.144761  0.091088\n",
       "21  109.469409 -0.005579  0.535738  0.130116  0.095175\n",
       "22   96.720282  0.016642  0.196443 -0.486145  0.090046\n",
       "23   58.780260  0.065048  0.548725 -0.192892  0.094991\n",
       "24  104.329838 -0.060309  0.435952 -0.204914  0.095352\n",
       "25  113.256847 -0.033569  0.283277  0.320838  0.095785\n",
       "26  100.995101  0.017117  0.659542  0.135914  0.090872\n",
       "27  112.526022  0.021746  0.329150 -0.030793  0.097180\n",
       "28  112.581981  0.014279  0.468894 -0.086904  0.098755\n",
       "29  114.519047  0.015638  0.365781 -0.283815  0.094740\n",
       "30   75.913800  0.100824  0.311442  0.156187  0.094485\n",
       "31   73.512892  0.035068  0.211150 -0.153345  0.091626\n",
       "32  100.164544  0.012818  0.312888  0.227823  0.086092\n",
       "33  106.633707  0.030955  0.505708 -0.134451  0.095304\n",
       "34   78.271780  0.006213  0.408556  0.048438  0.094505\n",
       "35  111.083018 -0.064990  0.445026 -0.148549  0.091513\n",
       "36   76.579734  0.144600  0.505266  0.042897  0.090022\n",
       "37  122.726522  0.021658  0.430761 -0.028441  0.065235"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_HH_bic = []\n",
    "model_HH_drift = []\n",
    "model_HH_noise = []\n",
    "model_HH_bias = []\n",
    "model_HH_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data_HH.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_HH_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_HH_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_HH_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_HH_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_HH_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_HH_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_HH_bic, \"drift\":model_HH_drift, \"noise\":model_HH_noise, \"bias\":model_HH_bias, \"ndt\":model_HH_ndt}\n",
    "indiv_model_HH = pd.DataFrame(data=d)\n",
    "indiv_model_HH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91.772345</td>\n",
       "      <td>0.070539</td>\n",
       "      <td>0.352714</td>\n",
       "      <td>-0.430345</td>\n",
       "      <td>0.098844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>99.114341</td>\n",
       "      <td>0.013988</td>\n",
       "      <td>0.256287</td>\n",
       "      <td>0.332850</td>\n",
       "      <td>0.093294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.871214</td>\n",
       "      <td>0.009313</td>\n",
       "      <td>0.297941</td>\n",
       "      <td>0.406765</td>\n",
       "      <td>0.092996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.612432</td>\n",
       "      <td>0.054543</td>\n",
       "      <td>0.255130</td>\n",
       "      <td>-0.386420</td>\n",
       "      <td>0.095831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>116.913835</td>\n",
       "      <td>0.009136</td>\n",
       "      <td>0.425835</td>\n",
       "      <td>-0.063608</td>\n",
       "      <td>0.088731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>96.738258</td>\n",
       "      <td>0.046746</td>\n",
       "      <td>0.474798</td>\n",
       "      <td>-0.155912</td>\n",
       "      <td>0.089737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>112.535674</td>\n",
       "      <td>0.031572</td>\n",
       "      <td>0.694860</td>\n",
       "      <td>0.357519</td>\n",
       "      <td>0.002156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>98.466287</td>\n",
       "      <td>0.020565</td>\n",
       "      <td>0.326964</td>\n",
       "      <td>-0.139791</td>\n",
       "      <td>0.032936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>110.898628</td>\n",
       "      <td>0.045166</td>\n",
       "      <td>0.352785</td>\n",
       "      <td>-0.390070</td>\n",
       "      <td>0.083022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>108.728792</td>\n",
       "      <td>0.017339</td>\n",
       "      <td>0.295952</td>\n",
       "      <td>-0.306112</td>\n",
       "      <td>0.090736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>110.171035</td>\n",
       "      <td>0.014444</td>\n",
       "      <td>0.544271</td>\n",
       "      <td>-0.123180</td>\n",
       "      <td>0.074360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>108.400054</td>\n",
       "      <td>0.027096</td>\n",
       "      <td>0.471669</td>\n",
       "      <td>0.165462</td>\n",
       "      <td>0.091493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>83.163356</td>\n",
       "      <td>0.035073</td>\n",
       "      <td>0.318983</td>\n",
       "      <td>0.200468</td>\n",
       "      <td>0.097465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>102.619703</td>\n",
       "      <td>0.022938</td>\n",
       "      <td>0.349925</td>\n",
       "      <td>-0.054464</td>\n",
       "      <td>0.081169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>87.646816</td>\n",
       "      <td>0.021152</td>\n",
       "      <td>0.138318</td>\n",
       "      <td>0.517715</td>\n",
       "      <td>0.095374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>94.379422</td>\n",
       "      <td>0.028355</td>\n",
       "      <td>0.358105</td>\n",
       "      <td>-0.361352</td>\n",
       "      <td>0.082250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>96.728715</td>\n",
       "      <td>0.010664</td>\n",
       "      <td>0.149023</td>\n",
       "      <td>0.448310</td>\n",
       "      <td>0.097900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>94.075696</td>\n",
       "      <td>0.009335</td>\n",
       "      <td>0.225889</td>\n",
       "      <td>-0.010394</td>\n",
       "      <td>0.096497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>107.083527</td>\n",
       "      <td>0.014631</td>\n",
       "      <td>0.365046</td>\n",
       "      <td>-0.159380</td>\n",
       "      <td>0.098446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>91.199779</td>\n",
       "      <td>0.035013</td>\n",
       "      <td>0.219831</td>\n",
       "      <td>-0.027273</td>\n",
       "      <td>0.097691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>106.827297</td>\n",
       "      <td>0.041118</td>\n",
       "      <td>0.397252</td>\n",
       "      <td>-0.253474</td>\n",
       "      <td>0.091491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>81.159358</td>\n",
       "      <td>0.086196</td>\n",
       "      <td>0.465548</td>\n",
       "      <td>-0.207649</td>\n",
       "      <td>0.095548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>105.811028</td>\n",
       "      <td>0.057574</td>\n",
       "      <td>0.330605</td>\n",
       "      <td>-0.190201</td>\n",
       "      <td>0.092092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>77.885312</td>\n",
       "      <td>0.034735</td>\n",
       "      <td>0.658735</td>\n",
       "      <td>-0.327976</td>\n",
       "      <td>0.094117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>82.477696</td>\n",
       "      <td>0.063377</td>\n",
       "      <td>0.478275</td>\n",
       "      <td>-0.120057</td>\n",
       "      <td>0.093046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>101.142887</td>\n",
       "      <td>0.018270</td>\n",
       "      <td>0.198262</td>\n",
       "      <td>0.559348</td>\n",
       "      <td>0.094168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>100.109824</td>\n",
       "      <td>0.051802</td>\n",
       "      <td>0.566909</td>\n",
       "      <td>-0.035268</td>\n",
       "      <td>0.099649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>115.303884</td>\n",
       "      <td>0.016557</td>\n",
       "      <td>0.349791</td>\n",
       "      <td>-0.141562</td>\n",
       "      <td>0.090578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>87.422930</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.239713</td>\n",
       "      <td>0.011639</td>\n",
       "      <td>0.051214</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>109.070810</td>\n",
       "      <td>0.015016</td>\n",
       "      <td>0.379043</td>\n",
       "      <td>0.133350</td>\n",
       "      <td>0.051797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>84.304726</td>\n",
       "      <td>0.027742</td>\n",
       "      <td>0.206098</td>\n",
       "      <td>0.361651</td>\n",
       "      <td>0.099617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>103.348674</td>\n",
       "      <td>0.056762</td>\n",
       "      <td>0.346413</td>\n",
       "      <td>-0.011353</td>\n",
       "      <td>0.085642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>116.805254</td>\n",
       "      <td>0.016316</td>\n",
       "      <td>0.308684</td>\n",
       "      <td>-0.020041</td>\n",
       "      <td>0.080055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>88.436979</td>\n",
       "      <td>0.014929</td>\n",
       "      <td>0.266517</td>\n",
       "      <td>0.210895</td>\n",
       "      <td>0.096650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>79.132801</td>\n",
       "      <td>0.008140</td>\n",
       "      <td>0.162957</td>\n",
       "      <td>0.515343</td>\n",
       "      <td>0.073435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>101.911335</td>\n",
       "      <td>0.037337</td>\n",
       "      <td>0.373872</td>\n",
       "      <td>-0.042374</td>\n",
       "      <td>0.097618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>83.009263</td>\n",
       "      <td>0.036354</td>\n",
       "      <td>0.301760</td>\n",
       "      <td>0.494082</td>\n",
       "      <td>0.098001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>80.542531</td>\n",
       "      <td>0.005389</td>\n",
       "      <td>0.088862</td>\n",
       "      <td>0.749548</td>\n",
       "      <td>0.087012</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           bic     drift     noise      bias       ndt\n",
       "0    91.772345  0.070539  0.352714 -0.430345  0.098844\n",
       "1    99.114341  0.013988  0.256287  0.332850  0.093294\n",
       "2   110.871214  0.009313  0.297941  0.406765  0.092996\n",
       "3   104.612432  0.054543  0.255130 -0.386420  0.095831\n",
       "4   116.913835  0.009136  0.425835 -0.063608  0.088731\n",
       "5    96.738258  0.046746  0.474798 -0.155912  0.089737\n",
       "6   112.535674  0.031572  0.694860  0.357519  0.002156\n",
       "7    98.466287  0.020565  0.326964 -0.139791  0.032936\n",
       "8   110.898628  0.045166  0.352785 -0.390070  0.083022\n",
       "9   108.728792  0.017339  0.295952 -0.306112  0.090736\n",
       "10  110.171035  0.014444  0.544271 -0.123180  0.074360\n",
       "11  108.400054  0.027096  0.471669  0.165462  0.091493\n",
       "12   83.163356  0.035073  0.318983  0.200468  0.097465\n",
       "13  102.619703  0.022938  0.349925 -0.054464  0.081169\n",
       "14   87.646816  0.021152  0.138318  0.517715  0.095374\n",
       "15   94.379422  0.028355  0.358105 -0.361352  0.082250\n",
       "16   96.728715  0.010664  0.149023  0.448310  0.097900\n",
       "17   94.075696  0.009335  0.225889 -0.010394  0.096497\n",
       "18  107.083527  0.014631  0.365046 -0.159380  0.098446\n",
       "19   91.199779  0.035013  0.219831 -0.027273  0.097691\n",
       "20  106.827297  0.041118  0.397252 -0.253474  0.091491\n",
       "21   81.159358  0.086196  0.465548 -0.207649  0.095548\n",
       "22  105.811028  0.057574  0.330605 -0.190201  0.092092\n",
       "23   77.885312  0.034735  0.658735 -0.327976  0.094117\n",
       "24   82.477696  0.063377  0.478275 -0.120057  0.093046\n",
       "25  101.142887  0.018270  0.198262  0.559348  0.094168\n",
       "26  100.109824  0.051802  0.566909 -0.035268  0.099649\n",
       "27  115.303884  0.016557  0.349791 -0.141562  0.090578\n",
       "28   87.422930  0.014586  0.239713  0.011639  0.051214\n",
       "29  109.070810  0.015016  0.379043  0.133350  0.051797\n",
       "30   84.304726  0.027742  0.206098  0.361651  0.099617\n",
       "31  103.348674  0.056762  0.346413 -0.011353  0.085642\n",
       "32  116.805254  0.016316  0.308684 -0.020041  0.080055\n",
       "33   88.436979  0.014929  0.266517  0.210895  0.096650\n",
       "34   79.132801  0.008140  0.162957  0.515343  0.073435\n",
       "35  101.911335  0.037337  0.373872 -0.042374  0.097618\n",
       "36   83.009263  0.036354  0.301760  0.494082  0.098001\n",
       "37   80.542531  0.005389  0.088862  0.749548  0.087012"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Placeholders\n",
    "model_HL_bic = []\n",
    "model_HL_drift = []\n",
    "model_HL_noise = []\n",
    "model_HL_bias = []\n",
    "model_HL_ndt = []\n",
    "\n",
    "# Iterate through subjects.\n",
    "subnums = np.sort(data_HL.subject.unique())\n",
    "for subnum in subnums:\n",
    "    \n",
    "    # Load\n",
    "    filename = ddmdir + \"fit_model_HL_\" + str(subnum) + \".txt\"\n",
    "    with open(filename, \"r\") as f:\n",
    "        model_loaded = eval(f.read())\n",
    "\n",
    "    # Negative Log Likelihood.\n",
    "    model_HL_bic.append(model_loaded.get_fit_result().value())\n",
    "    \n",
    "    # Fitted parameters.\n",
    "    model_HL_drift.append(model_loaded.parameters()['drift']['driftrate'])\n",
    "    model_HL_noise.append(model_loaded.parameters()['noise']['noise'])\n",
    "    model_HL_bias.append(model_loaded.parameters()['IC']['x0'])\n",
    "    model_HL_ndt.append(model_loaded.parameters()['overlay']['nondectime'])\n",
    "    \n",
    "d = {'bic':model_HL_bic, \"drift\":model_HL_drift, \"noise\":model_HL_noise, \"bias\":model_HL_bias, \"ndt\":model_HL_ndt}\n",
    "indiv_model_HL = pd.DataFrame(data=d)\n",
    "indiv_model_HL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Means of estimates and BIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>103.503709</td>\n",
       "      <td>0.021182</td>\n",
       "      <td>0.401266</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>0.084145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>2.859891</td>\n",
       "      <td>0.006105</td>\n",
       "      <td>0.018507</td>\n",
       "      <td>0.033172</td>\n",
       "      <td>0.003255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>97.898322</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.364992</td>\n",
       "      <td>-0.062730</td>\n",
       "      <td>0.077765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>109.109095</td>\n",
       "      <td>0.033148</td>\n",
       "      <td>0.437541</td>\n",
       "      <td>0.067305</td>\n",
       "      <td>0.090525</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean      103.503709  0.021182  0.401266  0.002288  0.084145\n",
       "se          2.859891  0.006105  0.018507  0.033172  0.003255\n",
       "ci_lower   97.898322  0.009216  0.364992 -0.062730  0.077765\n",
       "ci_upper  109.109095  0.033148  0.437541  0.067305  0.090525"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_HH = pd.DataFrame(data={\"mean\":indiv_model_HH.mean(), \n",
    "                                        \"se\":indiv_model_HH.sem(),\n",
    "                                        \"ci_lower\":indiv_model_HH.mean()-1.96*indiv_model_HH.sem(),\n",
    "                                        \"ci_upper\":indiv_model_HH.mean()+1.96*indiv_model_HH.sem()}).T\n",
    "summstats_model_HH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bic</th>\n",
       "      <th>drift</th>\n",
       "      <th>noise</th>\n",
       "      <th>bias</th>\n",
       "      <th>ndt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>98.179539</td>\n",
       "      <td>0.029995</td>\n",
       "      <td>0.341937</td>\n",
       "      <td>0.039650</td>\n",
       "      <td>0.085596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>se</th>\n",
       "      <td>1.893806</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.021982</td>\n",
       "      <td>0.050254</td>\n",
       "      <td>0.003258</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_lower</th>\n",
       "      <td>94.467680</td>\n",
       "      <td>0.023735</td>\n",
       "      <td>0.298853</td>\n",
       "      <td>-0.058849</td>\n",
       "      <td>0.079211</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ci_upper</th>\n",
       "      <td>101.891399</td>\n",
       "      <td>0.036255</td>\n",
       "      <td>0.385022</td>\n",
       "      <td>0.138148</td>\n",
       "      <td>0.091981</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 bic     drift     noise      bias       ndt\n",
       "mean       98.179539  0.029995  0.341937  0.039650  0.085596\n",
       "se          1.893806  0.003194  0.021982  0.050254  0.003258\n",
       "ci_lower   94.467680  0.023735  0.298853 -0.058849  0.079211\n",
       "ci_upper  101.891399  0.036255  0.385022  0.138148  0.091981"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summstats_model_HL = pd.DataFrame(data={\"mean\":indiv_model_HL.mean(), \n",
    "                                        \"se\":indiv_model_HL.sem(),\n",
    "                                        \"ci_lower\":indiv_model_HL.mean()-1.96*indiv_model_HL.sem(),\n",
    "                                        \"ci_upper\":indiv_model_HL.mean()+1.96*indiv_model_HL.sem()}).T\n",
    "summstats_model_HL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "est_diff_H = indiv_model_HH.noise - indiv_model_HL.noise\n",
    "plt.hist(est_diff_H)\n",
    "plt.plot((0, 0), (0, 9), scaley = False)\n",
    "plt.xlabel(\"Noise H High - Noise H Low\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
